<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.9.4" xml:lang="en-US">
  <compounddef id="_fully_connected_layer_8cc" kind="file" language="C++">
    <compoundname>FullyConnectedLayer.cc</compoundname>
    <includes refid="_fully_connected_layer_8h" local="yes">FullyConnectedLayer.h</includes>
    <includes local="no">wrappers/src/EigenDenseWrapper.h</includes>
    <includes refid="_layer_utils_8h" local="no">bolt/src/layers/LayerUtils.h</includes>
    <includes local="no">Eigen/src/Core/Map.h</includes>
    <includes local="no">Eigen/src/Core/util/Constants.h</includes>
    <includes local="no">algorithm</includes>
    <includes local="no">cassert</includes>
    <includes local="no">cmath</includes>
    <includes local="no">cstdlib</includes>
    <includes local="no">exception</includes>
    <includes local="no">numeric</includes>
    <includes local="no">random</includes>
    <includes local="no">unordered_map</includes>
    <incdepgraph>
      <node id="1">
        <label>bolt/src/layers/FullyConnectedLayer.cc</label>
        <link refid="_fully_connected_layer_8cc"/>
        <childnode refid="2" relation="include">
        </childnode>
        <childnode refid="43" relation="include">
        </childnode>
        <childnode refid="8" relation="include">
        </childnode>
        <childnode refid="44" relation="include">
        </childnode>
        <childnode refid="45" relation="include">
        </childnode>
        <childnode refid="16" relation="include">
        </childnode>
        <childnode refid="17" relation="include">
        </childnode>
        <childnode refid="38" relation="include">
        </childnode>
        <childnode refid="46" relation="include">
        </childnode>
        <childnode refid="40" relation="include">
        </childnode>
        <childnode refid="20" relation="include">
        </childnode>
        <childnode refid="42" relation="include">
        </childnode>
        <childnode refid="47" relation="include">
        </childnode>
      </node>
      <node id="2">
        <label>FullyConnectedLayer.h</label>
        <link refid="_fully_connected_layer_8h_source"/>
        <childnode refid="3" relation="include">
        </childnode>
        <childnode refid="4" relation="include">
        </childnode>
        <childnode refid="5" relation="include">
        </childnode>
        <childnode refid="8" relation="include">
        </childnode>
        <childnode refid="41" relation="include">
        </childnode>
        <childnode refid="14" relation="include">
        </childnode>
        <childnode refid="9" relation="include">
        </childnode>
        <childnode refid="35" relation="include">
        </childnode>
        <childnode refid="13" relation="include">
        </childnode>
        <childnode refid="21" relation="include">
        </childnode>
        <childnode refid="42" relation="include">
        </childnode>
      </node>
      <node id="5">
        <label>LayerConfig.h</label>
        <link refid="_layer_config_8h_source"/>
        <childnode refid="6" relation="include">
        </childnode>
        <childnode refid="7" relation="include">
        </childnode>
        <childnode refid="8" relation="include">
        </childnode>
        <childnode refid="33" relation="include">
        </childnode>
        <childnode refid="30" relation="include">
        </childnode>
        <childnode refid="38" relation="include">
        </childnode>
        <childnode refid="40" relation="include">
        </childnode>
        <childnode refid="18" relation="include">
        </childnode>
        <childnode refid="24" relation="include">
        </childnode>
      </node>
      <node id="8">
        <label>LayerUtils.h</label>
        <link refid="_layer_utils_8h_source"/>
        <childnode refid="4" relation="include">
        </childnode>
        <childnode refid="9" relation="include">
        </childnode>
        <childnode refid="28" relation="include">
        </childnode>
        <childnode refid="29" relation="include">
        </childnode>
        <childnode refid="30" relation="include">
        </childnode>
        <childnode refid="32" relation="include">
        </childnode>
        <childnode refid="24" relation="include">
        </childnode>
        <childnode refid="25" relation="include">
        </childnode>
        <childnode refid="26" relation="include">
        </childnode>
      </node>
      <node id="41">
        <label>bolt/src/layers/Optimizer.h</label>
        <link refid="_optimizer_8h_source"/>
        <childnode refid="13" relation="include">
        </childnode>
        <childnode refid="27" relation="include">
        </childnode>
      </node>
      <node id="33">
        <label>SamplingConfig.h</label>
        <link refid="_sampling_config_8h_source"/>
        <childnode refid="34" relation="include">
        </childnode>
        <childnode refid="10" relation="include">
        </childnode>
        <childnode refid="9" relation="include">
        </childnode>
        <childnode refid="28" relation="include">
        </childnode>
        <childnode refid="11" relation="include">
        </childnode>
        <childnode refid="35" relation="include">
        </childnode>
        <childnode refid="38" relation="include">
        </childnode>
        <childnode refid="19" relation="include">
        </childnode>
        <childnode refid="39" relation="include">
        </childnode>
        <childnode refid="24" relation="include">
        </childnode>
      </node>
      <node id="14">
        <label>bolt_vector/src/BoltVector.h</label>
        <link refid="_bolt_vector_8h_source"/>
        <childnode refid="6" relation="include">
        </childnode>
        <childnode refid="15" relation="include">
        </childnode>
        <childnode refid="16" relation="include">
        </childnode>
        <childnode refid="17" relation="include">
        </childnode>
        <childnode refid="13" relation="include">
        </childnode>
        <childnode refid="18" relation="include">
        </childnode>
        <childnode refid="19" relation="include">
        </childnode>
        <childnode refid="20" relation="include">
        </childnode>
        <childnode refid="21" relation="include">
        </childnode>
        <childnode refid="22" relation="include">
        </childnode>
        <childnode refid="23" relation="include">
        </childnode>
        <childnode refid="24" relation="include">
        </childnode>
        <childnode refid="25" relation="include">
        </childnode>
        <childnode refid="26" relation="include">
        </childnode>
        <childnode refid="27" relation="include">
        </childnode>
      </node>
      <node id="9">
        <label>hashing/src/DWTA.h</label>
        <link refid="_d_w_t_a_8h_source"/>
        <childnode refid="10" relation="include">
        </childnode>
        <childnode refid="4" relation="include">
        </childnode>
        <childnode refid="11" relation="include">
        </childnode>
        <childnode refid="27" relation="include">
        </childnode>
      </node>
      <node id="28">
        <label>hashing/src/FastSRP.h</label>
        <link refid="_fast_s_r_p_8h_source"/>
        <childnode refid="10" relation="include">
        </childnode>
        <childnode refid="4" relation="include">
        </childnode>
        <childnode refid="11" relation="include">
        </childnode>
        <childnode refid="13" relation="include">
        </childnode>
      </node>
      <node id="11">
        <label>HashFunction.h</label>
        <link refid="_hash_function_8h_source"/>
        <childnode refid="10" relation="include">
        </childnode>
        <childnode refid="12" relation="include">
        </childnode>
        <childnode refid="14" relation="include">
        </childnode>
      </node>
      <node id="12">
        <label>HashUtils.h</label>
        <link refid="_hash_utils_8h_source"/>
        <childnode refid="13" relation="include">
        </childnode>
      </node>
      <node id="29">
        <label>hashing/src/SRP.h</label>
        <link refid="_s_r_p_8h_source"/>
        <childnode refid="11" relation="include">
        </childnode>
        <childnode refid="13" relation="include">
        </childnode>
        <childnode refid="27" relation="include">
        </childnode>
      </node>
      <node id="36">
        <label>HashTable.h</label>
        <link refid="_hash_table_8h_source"/>
        <childnode refid="10" relation="include">
        </childnode>
        <childnode refid="13" relation="include">
        </childnode>
        <childnode refid="37" relation="include">
        </childnode>
        <childnode refid="27" relation="include">
        </childnode>
      </node>
      <node id="35">
        <label>hashtable/src/SampledHashTable.h</label>
        <link refid="_sampled_hash_table_8h_source"/>
        <childnode refid="10" relation="include">
        </childnode>
        <childnode refid="4" relation="include">
        </childnode>
        <childnode refid="36" relation="include">
        </childnode>
        <childnode refid="18" relation="include">
        </childnode>
        <childnode refid="23" relation="include">
        </childnode>
        <childnode refid="37" relation="include">
        </childnode>
        <childnode refid="27" relation="include">
        </childnode>
      </node>
      <node id="30">
        <label>utils/StringManipulation.h</label>
        <link refid="_string_manipulation_8h_source"/>
        <childnode refid="25" relation="include">
        </childnode>
        <childnode refid="31" relation="include">
        </childnode>
      </node>
      <node id="44">
        <label>Eigen/src/Core/Map.h</label>
      </node>
      <node id="45">
        <label>Eigen/src/Core/util/Constants.h</label>
      </node>
      <node id="16">
        <label>algorithm</label>
      </node>
      <node id="17">
        <label>cassert</label>
      </node>
      <node id="32">
        <label>cctype</label>
      </node>
      <node id="6">
        <label>cereal/access.hpp</label>
      </node>
      <node id="15">
        <label>cereal/cereal.hpp</label>
      </node>
      <node id="34">
        <label>cereal/types/base_class.hpp</label>
      </node>
      <node id="3">
        <label>cereal/types/memory.hpp</label>
      </node>
      <node id="7">
        <label>cereal/types/optional.hpp</label>
      </node>
      <node id="10">
        <label>cereal/types/polymorphic.hpp</label>
      </node>
      <node id="4">
        <label>cereal/types/vector.hpp</label>
      </node>
      <node id="38">
        <label>cmath</label>
      </node>
      <node id="13">
        <label>cstdint</label>
      </node>
      <node id="46">
        <label>cstdlib</label>
      </node>
      <node id="40">
        <label>exception</label>
      </node>
      <node id="18">
        <label>iostream</label>
      </node>
      <node id="19">
        <label>limits</label>
      </node>
      <node id="39">
        <label>memory</label>
      </node>
      <node id="20">
        <label>numeric</label>
      </node>
      <node id="21">
        <label>optional</label>
      </node>
      <node id="22">
        <label>queue</label>
      </node>
      <node id="42">
        <label>random</label>
      </node>
      <node id="23">
        <label>sstream</label>
      </node>
      <node id="24">
        <label>stdexcept</label>
      </node>
      <node id="25">
        <label>string</label>
      </node>
      <node id="31">
        <label>string_view</label>
      </node>
      <node id="47">
        <label>unordered_map</label>
      </node>
      <node id="37">
        <label>unordered_set</label>
      </node>
      <node id="26">
        <label>utility</label>
      </node>
      <node id="27">
        <label>vector</label>
      </node>
      <node id="43">
        <label>wrappers/src/EigenDenseWrapper.h</label>
      </node>
    </incdepgraph>
    <innernamespace refid="namespacethirdai">thirdai</innernamespace>
    <innernamespace refid="namespacethirdai_1_1bolt">thirdai::bolt</innernamespace>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
    </detaileddescription>
    <programlisting>
<codeline lineno="1"><highlight class="preprocessor">#include<sp/>&quot;FullyConnectedLayer.h&quot;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="2"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;wrappers/src/EigenDenseWrapper.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="3"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;bolt/src/layers/LayerUtils.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="4"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;Eigen/src/Core/Map.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="5"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;Eigen/src/Core/util/Constants.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="6"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;algorithm&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="7"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;cassert&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="8"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;cmath&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="9"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;cstdlib&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="10"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;exception&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="11"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;numeric&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="12"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;random&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="13"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;unordered_map&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="14"><highlight class="normal"></highlight></codeline>
<codeline lineno="15"><highlight class="normal"></highlight><highlight class="keyword">namespace<sp/></highlight><highlight class="normal">thirdai::bolt<sp/>{</highlight></codeline>
<codeline lineno="16"><highlight class="normal"></highlight></codeline>
<codeline lineno="17"><highlight class="normal">FullyConnectedLayer::FullyConnectedLayer(</highlight></codeline>
<codeline lineno="18"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>FullyConnectedLayerConfig&amp;<sp/>config,<sp/>uint64_t<sp/>prev_dim,</highlight></codeline>
<codeline lineno="19"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>is_distributed)</highlight></codeline>
<codeline lineno="20"><highlight class="normal"><sp/><sp/><sp/><sp/>:<sp/>_dim(config.getDim()),</highlight></codeline>
<codeline lineno="21"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>_prev_dim(prev_dim),</highlight></codeline>
<codeline lineno="22"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>_sparse_dim(config.getSparsity()<sp/>*<sp/>config.getDim()),</highlight></codeline>
<codeline lineno="23"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>_sparsity(config.getSparsity()),</highlight></codeline>
<codeline lineno="24"><highlight class="normal"></highlight></codeline>
<codeline lineno="25"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>trainable<sp/>parameter<sp/>not<sp/>present<sp/>in<sp/>config<sp/>file</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="26"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO(Shubh)<sp/>:<sp/>should<sp/>we<sp/>add<sp/>a<sp/>trainable<sp/>parameter<sp/>to<sp/>the<sp/>config<sp/>file?</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="27"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>_trainable(true),</highlight></codeline>
<codeline lineno="28"><highlight class="normal"></highlight></codeline>
<codeline lineno="29"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>_act_func(config.getActFunc()),</highlight></codeline>
<codeline lineno="30"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>_weights(config.getDim()<sp/>*<sp/>prev_dim),</highlight></codeline>
<codeline lineno="31"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>_biases(config.getDim()),</highlight></codeline>
<codeline lineno="32"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>_is_distributed(is_distributed),</highlight></codeline>
<codeline lineno="33"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>_sampling_mode(BoltSamplingMode::LSH),</highlight></codeline>
<codeline lineno="34"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>_use_sparse_sparse_optimization(</highlight></codeline>
<codeline lineno="35"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>config.shouldUseSparseSparseOptimization()),</highlight></codeline>
<codeline lineno="36"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>_prev_is_active(prev_dim,<sp/>false),</highlight></codeline>
<codeline lineno="37"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>_is_active(config.getDim(),<sp/>false)<sp/>{</highlight></codeline>
<codeline lineno="38"><highlight class="normal"><sp/><sp/>std::random_device<sp/>rd;</highlight></codeline>
<codeline lineno="39"><highlight class="normal"><sp/><sp/>std::default_random_engine<sp/>eng(rd());</highlight></codeline>
<codeline lineno="40"><highlight class="normal"><sp/><sp/>std::normal_distribution&lt;float&gt;<sp/>dist(0.0,<sp/>0.01);</highlight></codeline>
<codeline lineno="41"><highlight class="normal"></highlight></codeline>
<codeline lineno="42"><highlight class="normal"><sp/><sp/>std::generate(_weights.begin(),<sp/>_weights.end(),<sp/>[&amp;]()<sp/>{<sp/>return<sp/>dist(eng);<sp/>});</highlight></codeline>
<codeline lineno="43"><highlight class="normal"><sp/><sp/>std::generate(_biases.begin(),<sp/>_biases.end(),<sp/>[&amp;]()<sp/>{<sp/>return<sp/>dist(eng);<sp/>});</highlight></codeline>
<codeline lineno="44"><highlight class="normal"></highlight></codeline>
<codeline lineno="45"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(_sparsity<sp/>&lt;<sp/>1.0)<sp/>{</highlight></codeline>
<codeline lineno="46"><highlight class="normal"><sp/><sp/><sp/><sp/>initSamplingDatastructures(config.getSamplingConfig(),<sp/>rd);</highlight></codeline>
<codeline lineno="47"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="48"><highlight class="normal"></highlight></codeline>
<codeline lineno="49"><highlight class="normal"><sp/><sp/>initOptimizer();</highlight></codeline>
<codeline lineno="50"><highlight class="normal"></highlight></codeline>
<codeline lineno="51"><highlight class="normal"><sp/><sp/>initActiveNeuronsTrackers();</highlight></codeline>
<codeline lineno="52"><highlight class="normal">}</highlight></codeline>
<codeline lineno="53"><highlight class="normal"></highlight></codeline>
<codeline lineno="54"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::forward(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>BoltVector&amp;<sp/>input,<sp/>BoltVector&amp;<sp/>output,</highlight></codeline>
<codeline lineno="55"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>BoltVector*<sp/>labels)<sp/>{</highlight></codeline>
<codeline lineno="56"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO(Nicholas):<sp/>This<sp/>can<sp/>be<sp/>removed<sp/>when<sp/>we<sp/>deprecate<sp/>the<sp/>old<sp/>bolt<sp/>api.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="57"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(input.hasGradients())<sp/>{</highlight></codeline>
<codeline lineno="58"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const_cast&lt;</highlight><highlight class="normal">BoltVector&amp;</highlight><highlight class="keyword">&gt;</highlight><highlight class="normal">(input).zeroOutGradients();</highlight></codeline>
<codeline lineno="59"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="60"><highlight class="normal"></highlight></codeline>
<codeline lineno="61"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(output.isDense())<sp/>{</highlight></codeline>
<codeline lineno="62"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(input.isDense())<sp/>{</highlight></codeline>
<codeline lineno="63"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>eigenDenseDenseForward(input,<sp/>output);</highlight></codeline>
<codeline lineno="64"><highlight class="normal"><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="65"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>forwardImpl&lt;</highlight><highlight class="comment">/*DENSE=*/</highlight><highlight class="keyword">true</highlight><highlight class="normal">,<sp/></highlight><highlight class="comment">/*PREV_DENSE=*/</highlight><highlight class="keyword">false</highlight><highlight class="normal">&gt;(input,<sp/>output,<sp/>labels);</highlight></codeline>
<codeline lineno="66"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="67"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="68"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(input.isDense())<sp/>{</highlight></codeline>
<codeline lineno="69"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>forwardImpl&lt;</highlight><highlight class="comment">/*DENSE=*/</highlight><highlight class="keyword">false</highlight><highlight class="normal">,<sp/></highlight><highlight class="comment">/*PREV_DENSE=*/</highlight><highlight class="keyword">true</highlight><highlight class="normal">&gt;(input,<sp/>output,<sp/>labels);</highlight></codeline>
<codeline lineno="70"><highlight class="normal"><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="71"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>forwardImpl&lt;</highlight><highlight class="comment">/*DENSE=*/</highlight><highlight class="keyword">false</highlight><highlight class="normal">,<sp/></highlight><highlight class="comment">/*PREV_DENSE=*/</highlight><highlight class="keyword">false</highlight><highlight class="normal">&gt;(input,<sp/>output,<sp/>labels);</highlight></codeline>
<codeline lineno="72"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="73"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="74"><highlight class="normal">}</highlight></codeline>
<codeline lineno="75"><highlight class="normal"></highlight></codeline>
<codeline lineno="76"><highlight class="normal"></highlight><highlight class="keyword">template</highlight><highlight class="normal"><sp/>&lt;</highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>DENSE,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>PREV_DENSE&gt;</highlight></codeline>
<codeline lineno="77"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::forwardImpl(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>BoltVector&amp;<sp/>input,</highlight></codeline>
<codeline lineno="78"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>BoltVector&amp;<sp/>output,</highlight></codeline>
<codeline lineno="79"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>BoltVector*<sp/>labels)<sp/>{</highlight></codeline>
<codeline lineno="80"><highlight class="normal"><sp/><sp/>assert((input.len<sp/>&lt;=<sp/>_prev_dim<sp/>&amp;&amp;<sp/>!PREV_DENSE)<sp/>||</highlight></codeline>
<codeline lineno="81"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>(input.len<sp/>==<sp/>_prev_dim<sp/>&amp;&amp;<sp/>PREV_DENSE));</highlight></codeline>
<codeline lineno="82"><highlight class="normal"><sp/><sp/>assert((input.active_neurons<sp/>==<sp/></highlight><highlight class="keyword">nullptr</highlight><highlight class="normal"><sp/>&amp;&amp;<sp/>PREV_DENSE)<sp/>||</highlight></codeline>
<codeline lineno="83"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>(input.active_neurons<sp/>!=<sp/></highlight><highlight class="keyword">nullptr</highlight><highlight class="normal"><sp/>&amp;&amp;<sp/>!PREV_DENSE));</highlight></codeline>
<codeline lineno="84"><highlight class="normal"><sp/><sp/>assert((output.len<sp/>&lt;=<sp/>_dim<sp/>&amp;&amp;<sp/>!DENSE)<sp/>||<sp/>(output.len<sp/>==<sp/>_dim<sp/>&amp;&amp;<sp/>DENSE));</highlight></codeline>
<codeline lineno="85"><highlight class="normal"><sp/><sp/>assert((output.active_neurons<sp/>==<sp/></highlight><highlight class="keyword">nullptr</highlight><highlight class="normal"><sp/>&amp;&amp;<sp/>DENSE)<sp/>||</highlight></codeline>
<codeline lineno="86"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>(output.active_neurons<sp/>!=<sp/></highlight><highlight class="keyword">nullptr</highlight><highlight class="normal"><sp/>&amp;&amp;<sp/>!DENSE));</highlight></codeline>
<codeline lineno="87"><highlight class="normal"><sp/><sp/>assert(labels<sp/>==<sp/></highlight><highlight class="keyword">nullptr</highlight><highlight class="normal"><sp/>||<sp/>labels-&gt;len<sp/>&gt;<sp/>0);</highlight></codeline>
<codeline lineno="88"><highlight class="normal"></highlight></codeline>
<codeline lineno="89"><highlight class="normal"><sp/><sp/>selectActiveNeurons&lt;DENSE,<sp/>PREV_DENSE&gt;(input,<sp/>output,<sp/>labels);</highlight></codeline>
<codeline lineno="90"><highlight class="normal"></highlight></codeline>
<codeline lineno="91"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>max_act<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="92"><highlight class="normal"><sp/><sp/>uint32_t<sp/>len_out<sp/>=<sp/>nonzerosInOutput&lt;DENSE&gt;();</highlight></codeline>
<codeline lineno="93"><highlight class="normal"></highlight></codeline>
<codeline lineno="94"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>active<sp/>neurons<sp/>are<sp/>for<sp/>updateParameters<sp/>so<sp/>we<sp/>only<sp/>mark<sp/>them<sp/>if<sp/>trainable</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="95"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(_trainable)<sp/>{</highlight></codeline>
<codeline lineno="96"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO(david)<sp/>this<sp/>is<sp/>not<sp/>needed<sp/>for<sp/>inference,<sp/>we<sp/>can<sp/>optionally<sp/>remove</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="97"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>this<sp/>with<sp/>some<sp/>refactoring<sp/>if<sp/>we<sp/>want<sp/>slightly<sp/>faster<sp/>inference</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="98"><highlight class="normal"><sp/><sp/><sp/><sp/>markActiveNeuronsForUpdate&lt;DENSE,<sp/>PREV_DENSE&gt;(input,<sp/>output,<sp/>len_out);</highlight></codeline>
<codeline lineno="99"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="100"><highlight class="normal"></highlight></codeline>
<codeline lineno="101"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>n<sp/>=<sp/>0;<sp/>n<sp/>&lt;<sp/>len_out;<sp/>n++)<sp/>{</highlight></codeline>
<codeline lineno="102"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Because<sp/>DENSE<sp/>is<sp/>known<sp/>at<sp/>compile<sp/>time<sp/>the<sp/>compiler<sp/>can<sp/>remove<sp/>this</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="103"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>conditional</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="104"><highlight class="normal"><sp/><sp/><sp/><sp/>uint64_t<sp/>act_neuron<sp/>=<sp/>output.activeNeuronAtIndex&lt;DENSE&gt;(n);</highlight></codeline>
<codeline lineno="105"><highlight class="normal"><sp/><sp/><sp/><sp/>assert(act_neuron<sp/>&lt;<sp/>_dim);</highlight></codeline>
<codeline lineno="106"><highlight class="normal"></highlight></codeline>
<codeline lineno="107"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>act<sp/>=<sp/>_biases[act_neuron];</highlight></codeline>
<codeline lineno="108"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>input.len;<sp/>i++)<sp/>{</highlight></codeline>
<codeline lineno="109"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Because<sp/>PREV_DENSE<sp/>is<sp/>known<sp/>at<sp/>compile<sp/>time<sp/>the<sp/>compiler<sp/>can<sp/>remove</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="110"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>this<sp/>conditional</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="111"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>uint32_t<sp/>prev_act_neuron<sp/>=<sp/>input.activeNeuronAtIndex&lt;PREV_DENSE&gt;(i);</highlight></codeline>
<codeline lineno="112"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>assert(prev_act_neuron<sp/>&lt;<sp/>_prev_dim);</highlight></codeline>
<codeline lineno="113"><highlight class="normal"></highlight></codeline>
<codeline lineno="114"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>act<sp/>+=<sp/>_weights[act_neuron<sp/>*<sp/>_prev_dim<sp/>+<sp/>prev_act_neuron]<sp/>*</highlight></codeline>
<codeline lineno="115"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>input.activations[i];</highlight></codeline>
<codeline lineno="116"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="117"><highlight class="normal"></highlight></codeline>
<codeline lineno="118"><highlight class="normal"><sp/><sp/><sp/><sp/>assert(!std::isnan(act));</highlight></codeline>
<codeline lineno="119"><highlight class="normal"></highlight></codeline>
<codeline lineno="120"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">switch</highlight><highlight class="normal"><sp/>(_act_func)<sp/>{</highlight></codeline>
<codeline lineno="121"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">case</highlight><highlight class="normal"><sp/>ActivationFunction::ReLU:</highlight></codeline>
<codeline lineno="122"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(act<sp/>&lt;<sp/>0)<sp/>{</highlight></codeline>
<codeline lineno="123"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>output.activations[n]<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="124"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="125"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>output.activations[n]<sp/>=<sp/>act;</highlight></codeline>
<codeline lineno="126"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="127"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">break</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="128"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">case</highlight><highlight class="normal"><sp/>ActivationFunction::Softmax:</highlight></codeline>
<codeline lineno="129"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>output.activations[n]<sp/>=<sp/>act;</highlight></codeline>
<codeline lineno="130"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(max_act<sp/>&lt;<sp/>act)<sp/>{</highlight></codeline>
<codeline lineno="131"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>max_act<sp/>=<sp/>act;</highlight></codeline>
<codeline lineno="132"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="133"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">break</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="134"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">case</highlight><highlight class="normal"><sp/>ActivationFunction::Sigmoid:</highlight></codeline>
<codeline lineno="135"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>output.activations[n]<sp/>=<sp/>1<sp/>/<sp/>(1<sp/>+<sp/>std::exp(-act));</highlight></codeline>
<codeline lineno="136"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">break</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="137"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">case</highlight><highlight class="normal"><sp/>ActivationFunction::Linear:</highlight></codeline>
<codeline lineno="138"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>output.activations[n]<sp/>=<sp/>act;</highlight></codeline>
<codeline lineno="139"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">break</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="140"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">case</highlight><highlight class="normal"><sp/>ActivationFunction::Tanh:</highlight></codeline>
<codeline lineno="141"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>output.activations[n]<sp/>=<sp/></highlight><highlight class="keyword">static_cast&lt;</highlight><highlight class="keywordtype">float</highlight><highlight class="keyword">&gt;</highlight><highlight class="normal">(std::tanh(act));</highlight></codeline>
<codeline lineno="142"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">break</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="143"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="144"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="145"><highlight class="normal"></highlight></codeline>
<codeline lineno="146"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(_act_func<sp/>==<sp/>ActivationFunction::Softmax)<sp/>{</highlight></codeline>
<codeline lineno="147"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>total<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="148"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>n<sp/>=<sp/>0;<sp/>n<sp/>&lt;<sp/>len_out;<sp/>n++)<sp/>{</highlight></codeline>
<codeline lineno="149"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>output.activations[n]<sp/>=<sp/>std::exp(output.activations[n]<sp/>-<sp/>max_act);</highlight></codeline>
<codeline lineno="150"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>total<sp/>+=<sp/>output.activations[n];</highlight></codeline>
<codeline lineno="151"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="152"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>n<sp/>=<sp/>0;<sp/>n<sp/>&lt;<sp/>len_out;<sp/>n++)<sp/>{</highlight></codeline>
<codeline lineno="153"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>output.activations[n]<sp/>/=<sp/>(total<sp/>+<sp/>EPS);</highlight></codeline>
<codeline lineno="154"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>assert(!std::isnan(output.activations[n]));</highlight></codeline>
<codeline lineno="155"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="156"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="157"><highlight class="normal">}</highlight></codeline>
<codeline lineno="158"><highlight class="normal"></highlight></codeline>
<codeline lineno="159"><highlight class="normal"></highlight><highlight class="keyword">template</highlight><highlight class="normal"><sp/>&lt;</highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>DENSE,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>PREV_DENSE&gt;</highlight></codeline>
<codeline lineno="160"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::markActiveNeuronsForUpdate(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>BoltVector&amp;<sp/>input,</highlight></codeline>
<codeline lineno="161"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>BoltVector&amp;<sp/>output,</highlight></codeline>
<codeline lineno="162"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>uint32_t<sp/>len_out)<sp/>{</highlight></codeline>
<codeline lineno="163"><highlight class="normal"><sp/><sp/>_prev_is_dense<sp/>=<sp/>PREV_DENSE;</highlight></codeline>
<codeline lineno="164"><highlight class="normal"><sp/><sp/>_this_is_dense<sp/>=<sp/>DENSE;</highlight></codeline>
<codeline lineno="165"><highlight class="normal"></highlight></codeline>
<codeline lineno="166"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">constexpr</highlight><highlight class="normal"><sp/>(!DENSE<sp/>&amp;&amp;<sp/>!PREV_DENSE)<sp/>{</highlight></codeline>
<codeline lineno="167"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>We<sp/>track<sp/>using<sp/>_active_pairs_array<sp/>even<sp/>if<sp/>we<sp/>are<sp/>using<sp/>the<sp/>sparse<sp/>sparse</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="168"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>optimization<sp/>because<sp/>it<sp/>allows<sp/>us<sp/>to<sp/>avoid<sp/>duplicate<sp/>weight<sp/>updates</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="169"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>during<sp/>updateParameters.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="170"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>cur_index<sp/>=<sp/>0;<sp/>cur_index<sp/>&lt;<sp/>len_out;<sp/>cur_index++)<sp/>{</highlight></codeline>
<codeline lineno="171"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>uint64_t<sp/>act_neuron<sp/>=<sp/>output.active_neurons[cur_index];</highlight></codeline>
<codeline lineno="172"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>prev_index<sp/>=<sp/>0;<sp/>prev_index<sp/>&lt;<sp/>input.len;<sp/>prev_index++)<sp/>{</highlight></codeline>
<codeline lineno="173"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>uint64_t<sp/>prev_act_neuron<sp/>=<sp/>input.active_neurons[prev_index];</highlight></codeline>
<codeline lineno="174"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_active_pairs_array[act_neuron<sp/>*<sp/>_prev_dim<sp/>+<sp/>prev_act_neuron]<sp/>=<sp/></highlight><highlight class="keyword">true</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="175"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="176"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="177"><highlight class="normal"></highlight></codeline>
<codeline lineno="178"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(_use_sparse_sparse_optimization)<sp/>{</highlight></codeline>
<codeline lineno="179"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>std::unique_ptr&lt;ActiveNeuronsPair&gt;<sp/>active_pairs<sp/>=</highlight></codeline>
<codeline lineno="180"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>std::make_unique&lt;ActiveNeuronsPair&gt;(std::vector&lt;uint64_t&gt;(),</highlight></codeline>
<codeline lineno="181"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>std::vector&lt;uint64_t&gt;());</highlight></codeline>
<codeline lineno="182"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>input.len;<sp/>i++)<sp/>{</highlight></codeline>
<codeline lineno="183"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>active_pairs-&gt;first.push_back(input.active_neurons[i]);</highlight></codeline>
<codeline lineno="184"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="185"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>n<sp/>=<sp/>0;<sp/>n<sp/>&lt;<sp/>len_out;<sp/>n++)<sp/>{</highlight></codeline>
<codeline lineno="186"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>active_pairs-&gt;second.push_back(output.active_neurons[n]);</highlight></codeline>
<codeline lineno="187"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="188"><highlight class="normal"></highlight><highlight class="preprocessor">#pragma<sp/>omp<sp/>critical</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="189"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>_active_pairs_raw.push_back(std::move(active_pairs));</highlight></codeline>
<codeline lineno="190"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="191"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="192"><highlight class="normal"></highlight></codeline>
<codeline lineno="193"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">constexpr</highlight><highlight class="normal"><sp/>(!DENSE)<sp/>{</highlight></codeline>
<codeline lineno="194"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>n<sp/>=<sp/>0;<sp/>n<sp/>&lt;<sp/>len_out;<sp/>n++)<sp/>{</highlight></codeline>
<codeline lineno="195"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>uint64_t<sp/>act_neuron<sp/>=<sp/>output.active_neurons[n];</highlight></codeline>
<codeline lineno="196"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>_is_active[act_neuron]<sp/>=<sp/></highlight><highlight class="keyword">true</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="197"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="198"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="199"><highlight class="normal"></highlight></codeline>
<codeline lineno="200"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">constexpr</highlight><highlight class="normal"><sp/>(!PREV_DENSE)<sp/>{</highlight></codeline>
<codeline lineno="201"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>input.len;<sp/>i++)<sp/>{</highlight></codeline>
<codeline lineno="202"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>uint64_t<sp/>act_neuron<sp/>=<sp/>input.active_neurons[i];</highlight></codeline>
<codeline lineno="203"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>_prev_is_active[act_neuron]<sp/>=<sp/></highlight><highlight class="keyword">true</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="204"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="205"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="206"><highlight class="normal">}</highlight></codeline>
<codeline lineno="207"><highlight class="normal"></highlight></codeline>
<codeline lineno="208"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>eigenSoftmax(Eigen::Map&lt;Eigen::VectorXf&gt;&amp;<sp/>outputs)<sp/>{</highlight></codeline>
<codeline lineno="209"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>max_act<sp/>=<sp/>outputs.maxCoeff();</highlight></codeline>
<codeline lineno="210"><highlight class="normal"><sp/><sp/>outputs<sp/>=<sp/>(outputs.array()<sp/>-<sp/>max_act).exp();</highlight></codeline>
<codeline lineno="211"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>sum<sp/>=<sp/>outputs.sum()<sp/>+<sp/>EPS;</highlight></codeline>
<codeline lineno="212"><highlight class="normal"><sp/><sp/>outputs.array()<sp/>/=<sp/>sum;</highlight></codeline>
<codeline lineno="213"><highlight class="normal">}</highlight></codeline>
<codeline lineno="214"><highlight class="normal"></highlight></codeline>
<codeline lineno="215"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::eigenDenseDenseForward(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>BoltVector&amp;<sp/>input,</highlight></codeline>
<codeline lineno="216"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>BoltVector&amp;<sp/>output)<sp/>{</highlight></codeline>
<codeline lineno="217"><highlight class="normal"><sp/><sp/>_prev_is_dense<sp/>=<sp/></highlight><highlight class="keyword">true</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="218"><highlight class="normal"><sp/><sp/>_this_is_dense<sp/>=<sp/></highlight><highlight class="keyword">true</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="219"><highlight class="normal"></highlight></codeline>
<codeline lineno="220"><highlight class="normal"><sp/><sp/>Eigen::Map&lt;</highlight></codeline>
<codeline lineno="221"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>Eigen::Matrix&lt;float,<sp/>Eigen::Dynamic,<sp/>Eigen::Dynamic,<sp/>Eigen::RowMajor&gt;&gt;</highlight></codeline>
<codeline lineno="222"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>eigen_weights(_weights.data(),<sp/>_dim,<sp/>_prev_dim);</highlight></codeline>
<codeline lineno="223"><highlight class="normal"><sp/><sp/>Eigen::Map&lt;Eigen::VectorXf&gt;<sp/>eigen_biases(_biases.data(),<sp/>_dim);</highlight></codeline>
<codeline lineno="224"><highlight class="normal"></highlight></codeline>
<codeline lineno="225"><highlight class="normal"><sp/><sp/>Eigen::Map&lt;Eigen::VectorXf&gt;<sp/>eigen_input(input.activations,<sp/>input.len);</highlight></codeline>
<codeline lineno="226"><highlight class="normal"><sp/><sp/>Eigen::Map&lt;Eigen::VectorXf&gt;<sp/>eigen_output(output.activations,<sp/>output.len);</highlight></codeline>
<codeline lineno="227"><highlight class="normal"></highlight></codeline>
<codeline lineno="228"><highlight class="normal"><sp/><sp/>eigen_output.noalias()<sp/>=<sp/>eigen_weights<sp/>*<sp/>eigen_input;</highlight></codeline>
<codeline lineno="229"><highlight class="normal"></highlight></codeline>
<codeline lineno="230"><highlight class="normal"><sp/><sp/>eigen_biases.array().addTo(eigen_output);</highlight></codeline>
<codeline lineno="231"><highlight class="normal"></highlight></codeline>
<codeline lineno="232"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">switch</highlight><highlight class="normal"><sp/>(_act_func)<sp/>{</highlight></codeline>
<codeline lineno="233"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">case</highlight><highlight class="normal"><sp/>ActivationFunction::ReLU:</highlight></codeline>
<codeline lineno="234"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>eigen_output<sp/>=<sp/>eigen_output.array().max(0.0);</highlight></codeline>
<codeline lineno="235"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">break</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="236"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">case</highlight><highlight class="normal"><sp/>ActivationFunction::Softmax:</highlight></codeline>
<codeline lineno="237"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>eigenSoftmax(eigen_output);</highlight></codeline>
<codeline lineno="238"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">break</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="239"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">case</highlight><highlight class="normal"><sp/>ActivationFunction::Linear:</highlight></codeline>
<codeline lineno="240"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">break</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="241"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">case</highlight><highlight class="normal"><sp/>ActivationFunction::Sigmoid:</highlight></codeline>
<codeline lineno="242"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>eigen_output<sp/>=<sp/>1<sp/>+<sp/>(-eigen_output.array()).exp();</highlight></codeline>
<codeline lineno="243"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>eigen_output<sp/>=<sp/>eigen_output.array().rsqrt();</highlight></codeline>
<codeline lineno="244"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">break</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="245"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">case</highlight><highlight class="normal"><sp/>ActivationFunction::Tanh:</highlight></codeline>
<codeline lineno="246"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>eigen_output<sp/>=<sp/>eigen_output.array().tanh();</highlight></codeline>
<codeline lineno="247"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">break</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="248"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="249"><highlight class="normal">}</highlight></codeline>
<codeline lineno="250"><highlight class="normal"></highlight></codeline>
<codeline lineno="251"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::backpropagate(BoltVector&amp;<sp/>input,<sp/>BoltVector&amp;<sp/>output)<sp/>{</highlight></codeline>
<codeline lineno="252"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(output.isDense())<sp/>{</highlight></codeline>
<codeline lineno="253"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(input.isDense())<sp/>{</highlight></codeline>
<codeline lineno="254"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>This<sp/>eigen<sp/>dense<sp/>dense<sp/>optimized<sp/>version<sp/>seems<sp/>to<sp/>give<sp/>speedup<sp/>in</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="255"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>certain<sp/>cases<sp/>but<sp/>not<sp/>all,<sp/>so<sp/>it<sp/>is<sp/>here<sp/>as<sp/>an<sp/>experimental<sp/>feature</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="256"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>that<sp/>can<sp/>be<sp/>enabled<sp/>when<sp/>desired.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="257"><highlight class="normal"></highlight><highlight class="preprocessor">#if<sp/>THIRDAI_USE_EIGEN_FOR_BACKPROPAGATE</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="258"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>eigenDenseDenseBackpropagate&lt;false&gt;(input,<sp/>output);</highlight></codeline>
<codeline lineno="259"><highlight class="normal"></highlight><highlight class="preprocessor">#else</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="260"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>backpropagateImpl&lt;false,<sp/>true,<sp/>true&gt;(input,<sp/>output);</highlight></codeline>
<codeline lineno="261"><highlight class="normal"></highlight><highlight class="preprocessor">#endif</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="262"><highlight class="normal"><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="263"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>backpropagateImpl&lt;false,<sp/>true,<sp/>false&gt;(input,<sp/>output);</highlight></codeline>
<codeline lineno="264"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="265"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="266"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(input.isDense())<sp/>{</highlight></codeline>
<codeline lineno="267"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>backpropagateImpl&lt;false,<sp/>false,<sp/>true&gt;(input,<sp/>output);</highlight></codeline>
<codeline lineno="268"><highlight class="normal"><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="269"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>backpropagateImpl&lt;false,<sp/>false,<sp/>false&gt;(input,<sp/>output);</highlight></codeline>
<codeline lineno="270"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="271"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="272"><highlight class="normal">}</highlight></codeline>
<codeline lineno="273"><highlight class="normal"></highlight></codeline>
<codeline lineno="274"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::backpropagateInputLayer(BoltVector&amp;<sp/>input,</highlight></codeline>
<codeline lineno="275"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>BoltVector&amp;<sp/>output)<sp/>{</highlight></codeline>
<codeline lineno="276"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(output.isDense())<sp/>{</highlight></codeline>
<codeline lineno="277"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(input.isDense())<sp/>{</highlight></codeline>
<codeline lineno="278"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>This<sp/>eigen<sp/>dense<sp/>dense<sp/>optimized<sp/>version<sp/>seems<sp/>to<sp/>give<sp/>speedup<sp/>in</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="279"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>certain<sp/>cases<sp/>but<sp/>not<sp/>all,<sp/>so<sp/>it<sp/>is<sp/>here<sp/>as<sp/>an<sp/>experimental<sp/>feature</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="280"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>that<sp/>can<sp/>be<sp/>enabled<sp/>when<sp/>desired.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="281"><highlight class="normal"></highlight><highlight class="preprocessor">#if<sp/>THIRDAI_USE_EIGEN_FOR_BACKPROP</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="282"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>eigenDenseDenseBackpropagate&lt;true&gt;(input,<sp/>output);</highlight></codeline>
<codeline lineno="283"><highlight class="normal"></highlight><highlight class="preprocessor">#else</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="284"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>backpropagateImpl&lt;</highlight><highlight class="comment">/*IS_INPUT=*/</highlight><highlight class="keyword">true</highlight><highlight class="normal">,<sp/></highlight><highlight class="comment">/*DENSE=*/</highlight><highlight class="keyword">true</highlight><highlight class="normal">,<sp/></highlight><highlight class="comment">/*PREV_DENSE=*/</highlight><highlight class="keyword">true</highlight><highlight class="normal">&gt;(</highlight></codeline>
<codeline lineno="285"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>input,<sp/>output);</highlight></codeline>
<codeline lineno="286"><highlight class="normal"></highlight><highlight class="preprocessor">#endif</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="287"><highlight class="normal"><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="288"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>backpropagateImpl&lt;</highlight><highlight class="comment">/*IS_INPUT=*/</highlight><highlight class="keyword">true</highlight><highlight class="normal">,<sp/></highlight><highlight class="comment">/*DENSE=*/</highlight><highlight class="keyword">true</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="289"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">/*PREV_DENSE=*/</highlight><highlight class="keyword">false</highlight><highlight class="normal">&gt;(input,<sp/>output);</highlight></codeline>
<codeline lineno="290"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="291"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="292"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(input.isDense())<sp/>{</highlight></codeline>
<codeline lineno="293"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>backpropagateImpl&lt;</highlight><highlight class="comment">/*IS_INPUT=*/</highlight><highlight class="keyword">true</highlight><highlight class="normal">,<sp/></highlight><highlight class="comment">/*DENSE=*/</highlight><highlight class="keyword">false</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="294"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">/*PREV_DENSE=*/</highlight><highlight class="keyword">true</highlight><highlight class="normal">&gt;(input,<sp/>output);</highlight></codeline>
<codeline lineno="295"><highlight class="normal"><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="296"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>backpropagateImpl&lt;</highlight><highlight class="comment">/*IS_INPUT=*/</highlight><highlight class="keyword">true</highlight><highlight class="normal">,<sp/></highlight><highlight class="comment">/*DENSE=*/</highlight><highlight class="keyword">false</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="297"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">/*PREV_DENSE=*/</highlight><highlight class="keyword">false</highlight><highlight class="normal">&gt;(input,<sp/>output);</highlight></codeline>
<codeline lineno="298"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="299"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="300"><highlight class="normal">}</highlight></codeline>
<codeline lineno="301"><highlight class="normal"></highlight></codeline>
<codeline lineno="302"><highlight class="normal"></highlight><highlight class="keyword">template</highlight><highlight class="normal"><sp/>&lt;</highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>FIRST_LAYER,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>DENSE,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>PREV_DENSE&gt;</highlight></codeline>
<codeline lineno="303"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::backpropagateImpl(BoltVector&amp;<sp/>input,</highlight></codeline>
<codeline lineno="304"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>BoltVector&amp;<sp/>output)<sp/>{</highlight></codeline>
<codeline lineno="305"><highlight class="normal"><sp/><sp/>assert((input.len<sp/>&lt;=<sp/>_prev_dim<sp/>&amp;&amp;<sp/>!PREV_DENSE)<sp/>||</highlight></codeline>
<codeline lineno="306"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>(input.len<sp/>==<sp/>_prev_dim<sp/>&amp;&amp;<sp/>PREV_DENSE));</highlight></codeline>
<codeline lineno="307"><highlight class="normal"><sp/><sp/>assert((input.active_neurons<sp/>==<sp/></highlight><highlight class="keyword">nullptr</highlight><highlight class="normal"><sp/>&amp;&amp;<sp/>PREV_DENSE)<sp/>||</highlight></codeline>
<codeline lineno="308"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>(input.active_neurons<sp/>!=<sp/></highlight><highlight class="keyword">nullptr</highlight><highlight class="normal"><sp/>&amp;&amp;<sp/>!PREV_DENSE));</highlight></codeline>
<codeline lineno="309"><highlight class="normal"><sp/><sp/>assert((output.len<sp/>&lt;=<sp/>_dim<sp/>&amp;&amp;<sp/>!DENSE)<sp/>||<sp/>(output.len<sp/>==<sp/>_dim<sp/>&amp;&amp;<sp/>DENSE));</highlight></codeline>
<codeline lineno="310"><highlight class="normal"><sp/><sp/>assert((output.active_neurons<sp/>==<sp/></highlight><highlight class="keyword">nullptr</highlight><highlight class="normal"><sp/>&amp;&amp;<sp/>DENSE)<sp/>||</highlight></codeline>
<codeline lineno="311"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>(output.active_neurons<sp/>!=<sp/></highlight><highlight class="keyword">nullptr</highlight><highlight class="normal"><sp/>&amp;&amp;<sp/>!DENSE));</highlight></codeline>
<codeline lineno="312"><highlight class="normal"><sp/><sp/>assert(_weight_optimizer.has_value()<sp/>&amp;&amp;<sp/>_bias_optimizer.has_value());</highlight></codeline>
<codeline lineno="313"><highlight class="normal"></highlight></codeline>
<codeline lineno="314"><highlight class="normal"><sp/><sp/>uint32_t<sp/>len_out<sp/>=<sp/>nonzerosInOutput&lt;DENSE&gt;();</highlight></codeline>
<codeline lineno="315"><highlight class="normal"></highlight></codeline>
<codeline lineno="316"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>n<sp/>=<sp/>0;<sp/>n<sp/>&lt;<sp/>len_out;<sp/>n++)<sp/>{</highlight></codeline>
<codeline lineno="317"><highlight class="normal"><sp/><sp/><sp/><sp/>assert(!std::isnan(output.gradients[n]));</highlight></codeline>
<codeline lineno="318"><highlight class="normal"><sp/><sp/><sp/><sp/>output.gradients[n]<sp/>*=<sp/>actFuncDerivative(output.activations[n],<sp/>_act_func);</highlight></codeline>
<codeline lineno="319"><highlight class="normal"></highlight></codeline>
<codeline lineno="320"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(output.gradients[n]<sp/>==<sp/>0.0)<sp/>{</highlight></codeline>
<codeline lineno="321"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Neurons<sp/>with<sp/>gradients<sp/>of<sp/>0<sp/>will<sp/>not<sp/>propagate<sp/>gradients<sp/>to<sp/>weights<sp/>or</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="322"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>the<sp/>previous<sp/>layer.<sp/>We<sp/>will<sp/>also<sp/>likely<sp/>have<sp/>a<sp/>number<sp/>of<sp/>0<sp/>gradients</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="323"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>with<sp/>ReLU.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="324"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">continue</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="325"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="326"><highlight class="normal"></highlight></codeline>
<codeline lineno="327"><highlight class="normal"><sp/><sp/><sp/><sp/>assert(!std::isnan(output.gradients[n]));</highlight></codeline>
<codeline lineno="328"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Because<sp/>DENSE<sp/>is<sp/>known<sp/>at<sp/>compile<sp/>time<sp/>the<sp/>compiler<sp/>can<sp/>remove<sp/>this</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="329"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>conditional</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="330"><highlight class="normal"><sp/><sp/><sp/><sp/>uint32_t<sp/>act_neuron<sp/>=<sp/>output.activeNeuronAtIndex&lt;DENSE&gt;(n);</highlight></codeline>
<codeline lineno="331"><highlight class="normal"><sp/><sp/><sp/><sp/>assert(act_neuron<sp/>&lt;<sp/>_dim);</highlight></codeline>
<codeline lineno="332"><highlight class="normal"></highlight></codeline>
<codeline lineno="333"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>input.len;<sp/>i++)<sp/>{</highlight></codeline>
<codeline lineno="334"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Because<sp/>PREV_DENSE<sp/>is<sp/>known<sp/>at<sp/>compile<sp/>time<sp/>the<sp/>compiler<sp/>can<sp/>remove</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="335"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>this<sp/>conditional</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="336"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>uint32_t<sp/>prev_act_neuron<sp/>=<sp/>input.activeNeuronAtIndex&lt;PREV_DENSE&gt;(i);</highlight></codeline>
<codeline lineno="337"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>assert(prev_act_neuron<sp/>&lt;<sp/>_prev_dim);</highlight></codeline>
<codeline lineno="338"><highlight class="normal"></highlight></codeline>
<codeline lineno="339"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>_weight_optimizer-&gt;gradients[act_neuron<sp/>*<sp/>_prev_dim<sp/>+<sp/>prev_act_neuron]<sp/>+=</highlight></codeline>
<codeline lineno="340"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>output.gradients[n]<sp/>*<sp/>input.activations[i];</highlight></codeline>
<codeline lineno="341"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">constexpr</highlight><highlight class="normal"><sp/>(!FIRST_LAYER)<sp/>{</highlight></codeline>
<codeline lineno="342"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>input.gradients[i]<sp/>+=</highlight></codeline>
<codeline lineno="343"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>output.gradients[n]<sp/>*</highlight></codeline>
<codeline lineno="344"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_weights[act_neuron<sp/>*<sp/>_prev_dim<sp/>+<sp/>prev_act_neuron];</highlight></codeline>
<codeline lineno="345"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="346"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="347"><highlight class="normal"><sp/><sp/><sp/><sp/>_bias_optimizer-&gt;gradients[act_neuron]<sp/>+=<sp/>output.gradients[n];</highlight></codeline>
<codeline lineno="348"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="349"><highlight class="normal">}</highlight></codeline>
<codeline lineno="350"><highlight class="normal"></highlight></codeline>
<codeline lineno="351"><highlight class="normal"></highlight><highlight class="keyword">template</highlight><highlight class="normal"><sp/>&lt;</highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>FIRST_LAYER&gt;</highlight></codeline>
<codeline lineno="352"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::eigenDenseDenseBackpropagate(BoltVector&amp;<sp/>input,</highlight></codeline>
<codeline lineno="353"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>BoltVector&amp;<sp/>output)<sp/>{</highlight></codeline>
<codeline lineno="354"><highlight class="normal"><sp/><sp/>assert(_weight_optimizer.has_value()<sp/>&amp;&amp;<sp/>_bias_optimizer.has_value());</highlight></codeline>
<codeline lineno="355"><highlight class="normal"></highlight></codeline>
<codeline lineno="356"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint32_t<sp/>n<sp/>=<sp/>0;<sp/>n<sp/>&lt;<sp/>output.len;<sp/>n++)<sp/>{</highlight></codeline>
<codeline lineno="357"><highlight class="normal"><sp/><sp/><sp/><sp/>output.gradients[n]<sp/>*=<sp/>actFuncDerivative(output.activations[n],<sp/>_act_func);</highlight></codeline>
<codeline lineno="358"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="359"><highlight class="normal"></highlight></codeline>
<codeline lineno="360"><highlight class="normal"><sp/><sp/>Eigen::Map&lt;</highlight></codeline>
<codeline lineno="361"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>Eigen::Matrix&lt;float,<sp/>Eigen::Dynamic,<sp/>Eigen::Dynamic,<sp/>Eigen::RowMajor&gt;&gt;</highlight></codeline>
<codeline lineno="362"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>eigen_weights(_weights.data(),<sp/>_dim,<sp/>_prev_dim);</highlight></codeline>
<codeline lineno="363"><highlight class="normal"><sp/><sp/>Eigen::Map&lt;</highlight></codeline>
<codeline lineno="364"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>Eigen::Matrix&lt;float,<sp/>Eigen::Dynamic,<sp/>Eigen::Dynamic,<sp/>Eigen::RowMajor&gt;&gt;</highlight></codeline>
<codeline lineno="365"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>eigen_weight_grad(_weight_optimizer-&gt;gradients.data(),<sp/>_dim,<sp/>_prev_dim);</highlight></codeline>
<codeline lineno="366"><highlight class="normal"></highlight></codeline>
<codeline lineno="367"><highlight class="normal"><sp/><sp/>Eigen::Map&lt;Eigen::VectorXf&gt;<sp/>eigen_bias_grad(_bias_optimizer-&gt;gradients.data(),</highlight></codeline>
<codeline lineno="368"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_dim);</highlight></codeline>
<codeline lineno="369"><highlight class="normal"></highlight></codeline>
<codeline lineno="370"><highlight class="normal"><sp/><sp/>Eigen::Map&lt;Eigen::VectorXf&gt;<sp/>eigen_input(input.activations,<sp/>input.len);</highlight></codeline>
<codeline lineno="371"><highlight class="normal"><sp/><sp/>Eigen::Map&lt;Eigen::VectorXf&gt;<sp/>eigen_output_grad(output.gradients,<sp/>output.len);</highlight></codeline>
<codeline lineno="372"><highlight class="normal"></highlight></codeline>
<codeline lineno="373"><highlight class="normal"><sp/><sp/>eigen_weight_grad<sp/>+=<sp/>eigen_output_grad<sp/>*<sp/>eigen_input.transpose();</highlight></codeline>
<codeline lineno="374"><highlight class="normal"><sp/><sp/>eigen_output_grad.array().addTo(eigen_bias_grad);</highlight></codeline>
<codeline lineno="375"><highlight class="normal"></highlight></codeline>
<codeline lineno="376"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">constexpr</highlight><highlight class="normal"><sp/>(!FIRST_LAYER)<sp/>{</highlight></codeline>
<codeline lineno="377"><highlight class="normal"><sp/><sp/><sp/><sp/>Eigen::Map&lt;</highlight></codeline>
<codeline lineno="378"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Eigen::Matrix&lt;float,<sp/>Eigen::Dynamic,<sp/>Eigen::Dynamic,<sp/>Eigen::RowMajor&gt;&gt;</highlight></codeline>
<codeline lineno="379"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>eigen_weights(_weights.data(),<sp/>_dim,<sp/>_prev_dim);</highlight></codeline>
<codeline lineno="380"><highlight class="normal"></highlight></codeline>
<codeline lineno="381"><highlight class="normal"><sp/><sp/><sp/><sp/>Eigen::Map&lt;Eigen::VectorXf&gt;<sp/>eigen_input_grad(input.gradients,<sp/>input.len);</highlight></codeline>
<codeline lineno="382"><highlight class="normal"></highlight></codeline>
<codeline lineno="383"><highlight class="normal"><sp/><sp/><sp/><sp/>eigen_input_grad.noalias()<sp/>=<sp/>eigen_output_grad.transpose()<sp/>*<sp/>eigen_weights;</highlight></codeline>
<codeline lineno="384"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="385"><highlight class="normal">}</highlight></codeline>
<codeline lineno="386"><highlight class="normal"></highlight></codeline>
<codeline lineno="387"><highlight class="normal"></highlight><highlight class="keyword">template</highlight><highlight class="normal"><sp/>&lt;</highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>DENSE,<sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>PREV_DENSE&gt;</highlight></codeline>
<codeline lineno="388"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::selectActiveNeurons(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>BoltVector&amp;<sp/>input,</highlight></codeline>
<codeline lineno="389"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>BoltVector&amp;<sp/>output,</highlight></codeline>
<codeline lineno="390"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>BoltVector*<sp/>labels)<sp/>{</highlight></codeline>
<codeline lineno="391"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">constexpr</highlight><highlight class="normal"><sp/>(DENSE)<sp/>{</highlight></codeline>
<codeline lineno="392"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="393"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="394"><highlight class="normal"></highlight></codeline>
<codeline lineno="395"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(useRandomSampling())<sp/>{</highlight></codeline>
<codeline lineno="396"><highlight class="normal"><sp/><sp/><sp/><sp/>randomNeuronSampling(input,<sp/>output,<sp/>labels);</highlight></codeline>
<codeline lineno="397"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="398"><highlight class="normal"><sp/><sp/><sp/><sp/>lshNeuronSampling&lt;PREV_DENSE&gt;(input,<sp/>output,<sp/>labels);</highlight></codeline>
<codeline lineno="399"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="400"><highlight class="normal">}</highlight></codeline>
<codeline lineno="401"><highlight class="normal"></highlight></codeline>
<codeline lineno="402"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>wrapAroundCopy(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>uint32_t*<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>src,<sp/>uint64_t<sp/>src_len,</highlight></codeline>
<codeline lineno="403"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>uint32_t*<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>dest,<sp/>uint64_t<sp/>copy_size,</highlight></codeline>
<codeline lineno="404"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>uint64_t<sp/>starting_offset)<sp/>{</highlight></codeline>
<codeline lineno="405"><highlight class="normal"><sp/><sp/>assert(starting_offset<sp/>&lt;<sp/>src_len);</highlight></codeline>
<codeline lineno="406"><highlight class="normal"><sp/><sp/>assert(copy_size<sp/>&lt;=<sp/>src_len);</highlight></codeline>
<codeline lineno="407"><highlight class="normal"></highlight></codeline>
<codeline lineno="408"><highlight class="normal"><sp/><sp/>uint64_t<sp/>length_to_end<sp/>=<sp/>std::min(src_len<sp/>-<sp/>starting_offset,<sp/>copy_size);</highlight></codeline>
<codeline lineno="409"><highlight class="normal"><sp/><sp/>uint64_t<sp/>length_of_remainder<sp/>=</highlight></codeline>
<codeline lineno="410"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>length_to_end<sp/>&lt;<sp/>copy_size<sp/>?<sp/>copy_size<sp/>-<sp/>length_to_end<sp/>:<sp/>0;</highlight></codeline>
<codeline lineno="411"><highlight class="normal"></highlight></codeline>
<codeline lineno="412"><highlight class="normal"><sp/><sp/>std::copy(src<sp/>+<sp/>starting_offset,<sp/>src<sp/>+<sp/>starting_offset<sp/>+<sp/>length_to_end,<sp/>dest);</highlight></codeline>
<codeline lineno="413"><highlight class="normal"><sp/><sp/>std::copy(src,<sp/>src<sp/>+<sp/>length_of_remainder,<sp/>dest<sp/>+<sp/>length_to_end);</highlight></codeline>
<codeline lineno="414"><highlight class="normal">}</highlight></codeline>
<codeline lineno="415"><highlight class="normal"></highlight></codeline>
<codeline lineno="416"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::randomNeuronSampling(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>BoltVector&amp;<sp/>input,</highlight></codeline>
<codeline lineno="417"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>BoltVector&amp;<sp/>output,</highlight></codeline>
<codeline lineno="418"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>BoltVector*<sp/>labels)<sp/>{</highlight></codeline>
<codeline lineno="419"><highlight class="normal"><sp/><sp/>uint32_t<sp/>label_len<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="420"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(labels)<sp/>{</highlight></codeline>
<codeline lineno="421"><highlight class="normal"><sp/><sp/><sp/><sp/>label_len<sp/>=<sp/>std::min&lt;uint64_t&gt;(labels-&gt;len,<sp/>_sparse_dim);</highlight></codeline>
<codeline lineno="422"><highlight class="normal"><sp/><sp/><sp/><sp/>std::copy(labels-&gt;active_neurons,<sp/>labels-&gt;active_neurons<sp/>+<sp/>label_len,</highlight></codeline>
<codeline lineno="423"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>output.active_neurons);</highlight></codeline>
<codeline lineno="424"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="425"><highlight class="normal"></highlight></codeline>
<codeline lineno="426"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>This<sp/>is<sp/>because<sp/>rand()<sp/>is<sp/>not<sp/>threadsafe<sp/>and<sp/>because<sp/>we<sp/>want<sp/>to<sp/>make<sp/>the</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="427"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>output<sp/>more<sp/>deterministic.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="428"><highlight class="normal"><sp/><sp/>uint64_t<sp/>random_offset<sp/>=</highlight></codeline>
<codeline lineno="429"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>hashing::HashUtils::simpleIntegerHash(</highlight></codeline>
<codeline lineno="430"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Hack<sp/>to<sp/>intepret<sp/>the<sp/>float<sp/>as<sp/>an<sp/>integer<sp/>without<sp/>doing<sp/>a</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="431"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>conversion.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="432"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>*</highlight><highlight class="keyword">reinterpret_cast&lt;</highlight><highlight class="normal">uint32_t*</highlight><highlight class="keyword">&gt;</highlight><highlight class="normal">(&amp;input.activations[0]))<sp/>%</highlight></codeline>
<codeline lineno="433"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>_dim;</highlight></codeline>
<codeline lineno="434"><highlight class="normal"></highlight></codeline>
<codeline lineno="435"><highlight class="normal"><sp/><sp/>uint64_t<sp/>neurons_to_sample<sp/>=<sp/>_sparse_dim<sp/>-<sp/>label_len;</highlight></codeline>
<codeline lineno="436"><highlight class="normal"></highlight></codeline>
<codeline lineno="437"><highlight class="normal"><sp/><sp/>wrapAroundCopy(</highlight><highlight class="comment">/*<sp/>src=<sp/>*/</highlight><highlight class="normal"><sp/>_rand_neurons.data(),<sp/></highlight><highlight class="comment">/*<sp/>src_len=<sp/>*/</highlight><highlight class="normal"><sp/>_dim,</highlight></codeline>
<codeline lineno="438"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">/*<sp/>dest=<sp/>*/</highlight><highlight class="normal"><sp/>output.active_neurons<sp/>+<sp/>label_len,</highlight></codeline>
<codeline lineno="439"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">/*<sp/>copy_size=<sp/>*/</highlight><highlight class="normal"><sp/>neurons_to_sample,</highlight></codeline>
<codeline lineno="440"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">/*<sp/>starting_offset=<sp/>*/</highlight><highlight class="normal"><sp/>random_offset);</highlight></codeline>
<codeline lineno="441"><highlight class="normal">}</highlight></codeline>
<codeline lineno="442"><highlight class="normal"></highlight></codeline>
<codeline lineno="443"><highlight class="normal"></highlight><highlight class="keyword">template</highlight><highlight class="normal"><sp/>&lt;</highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>PREV_DENSE&gt;</highlight></codeline>
<codeline lineno="444"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::lshNeuronSampling(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>BoltVector&amp;<sp/>input,</highlight></codeline>
<codeline lineno="445"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>BoltVector&amp;<sp/>output,</highlight></codeline>
<codeline lineno="446"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>BoltVector*<sp/>labels)<sp/>{</highlight></codeline>
<codeline lineno="447"><highlight class="normal"><sp/><sp/>std::unordered_set&lt;uint32_t&gt;<sp/>active_set;</highlight></codeline>
<codeline lineno="448"><highlight class="normal"></highlight></codeline>
<codeline lineno="449"><highlight class="normal"><sp/><sp/>uint32_t<sp/>label_len<sp/>=<sp/>labels<sp/>!=<sp/></highlight><highlight class="keyword">nullptr</highlight><highlight class="normal"><sp/>?<sp/>labels-&gt;len<sp/>:<sp/>0;</highlight></codeline>
<codeline lineno="450"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint32_t<sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>label_len;<sp/>i++)<sp/>{</highlight></codeline>
<codeline lineno="451"><highlight class="normal"><sp/><sp/><sp/><sp/>assert(labels-&gt;active_neurons[i]<sp/>&lt;<sp/>_dim);</highlight></codeline>
<codeline lineno="452"><highlight class="normal"><sp/><sp/><sp/><sp/>active_set.insert(labels-&gt;active_neurons[i]);</highlight></codeline>
<codeline lineno="453"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="454"><highlight class="normal"></highlight></codeline>
<codeline lineno="455"><highlight class="normal"><sp/><sp/>std::vector&lt;uint32_t&gt;<sp/>hashes(_hasher-&gt;numTables());</highlight></codeline>
<codeline lineno="456"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">constexpr</highlight><highlight class="normal"><sp/>(PREV_DENSE)<sp/>{</highlight></codeline>
<codeline lineno="457"><highlight class="normal"><sp/><sp/><sp/><sp/>_hasher-&gt;hashSingleDense(input.activations,<sp/>input.len,<sp/>hashes.data());</highlight></codeline>
<codeline lineno="458"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="459"><highlight class="normal"><sp/><sp/><sp/><sp/>_hasher-&gt;hashSingleSparse(input.active_neurons,<sp/>input.activations,</highlight></codeline>
<codeline lineno="460"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>input.len,<sp/>hashes.data());</highlight></codeline>
<codeline lineno="461"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="462"><highlight class="normal"></highlight></codeline>
<codeline lineno="463"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(_sampling_mode<sp/>==<sp/>BoltSamplingMode::FreezeHashTablesWithInsertions)<sp/>{</highlight></codeline>
<codeline lineno="476"><highlight class="normal"><sp/><sp/><sp/><sp/>_hash_table-&gt;queryAndInsertForInference(hashes.data(),<sp/>active_set,</highlight></codeline>
<codeline lineno="477"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_sparse_dim);</highlight></codeline>
<codeline lineno="478"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="479"><highlight class="normal"><sp/><sp/><sp/><sp/>_hash_table-&gt;queryBySet(hashes.data(),<sp/>active_set);</highlight></codeline>
<codeline lineno="480"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="481"><highlight class="normal"></highlight></codeline>
<codeline lineno="482"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(active_set.size()<sp/>&lt;<sp/>_sparse_dim)<sp/>{</highlight></codeline>
<codeline lineno="483"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>here<sp/>we<sp/>use<sp/>hashes[0]<sp/>as<sp/>our<sp/>random<sp/>number<sp/>because<sp/>rand()<sp/>is<sp/>not<sp/>thread</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="484"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>safe<sp/>and<sp/>we<sp/>want<sp/>to<sp/>have<sp/>deterministic<sp/>sampling.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="485"><highlight class="normal"><sp/><sp/><sp/><sp/>uint32_t<sp/>rand_offset<sp/>=<sp/>hashes.at(0)<sp/>%<sp/>_dim;</highlight></codeline>
<codeline lineno="486"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">while</highlight><highlight class="normal"><sp/>(active_set.size()<sp/>&lt;<sp/>_sparse_dim)<sp/>{</highlight></codeline>
<codeline lineno="487"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>active_set.insert(_rand_neurons[rand_offset++]);</highlight></codeline>
<codeline lineno="488"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>rand_offset<sp/>=<sp/>rand_offset<sp/>%<sp/>_dim;</highlight></codeline>
<codeline lineno="489"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="490"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="491"><highlight class="normal"></highlight></codeline>
<codeline lineno="492"><highlight class="normal"><sp/><sp/>uint32_t<sp/>cnt<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="493"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint32_t<sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>label_len;<sp/>i++)<sp/>{</highlight></codeline>
<codeline lineno="494"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(cnt<sp/>==<sp/>_sparse_dim)<sp/>{</highlight></codeline>
<codeline lineno="495"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">break</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="496"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="497"><highlight class="normal"><sp/><sp/><sp/><sp/>output.active_neurons[cnt++]<sp/>=<sp/>labels-&gt;active_neurons[i];</highlight></codeline>
<codeline lineno="498"><highlight class="normal"><sp/><sp/><sp/><sp/>active_set.erase(labels-&gt;active_neurons[i]);</highlight></codeline>
<codeline lineno="499"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="500"><highlight class="normal"></highlight></codeline>
<codeline lineno="501"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>x<sp/>:<sp/>active_set)<sp/>{</highlight></codeline>
<codeline lineno="502"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(cnt<sp/>==<sp/>_sparse_dim)<sp/>{</highlight></codeline>
<codeline lineno="503"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">break</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="504"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="505"><highlight class="normal"><sp/><sp/><sp/><sp/>assert(x<sp/>&lt;<sp/>_dim);</highlight></codeline>
<codeline lineno="506"><highlight class="normal"><sp/><sp/><sp/><sp/>output.active_neurons[cnt++]<sp/>=<sp/>x;</highlight></codeline>
<codeline lineno="507"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="508"><highlight class="normal">}</highlight></codeline>
<codeline lineno="509"><highlight class="normal"></highlight></codeline>
<codeline lineno="510"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::updateParameters(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>lr,<sp/>uint32_t<sp/>iter,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B1,</highlight></codeline>
<codeline lineno="511"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B2,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>eps)<sp/>{</highlight></codeline>
<codeline lineno="512"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B1_bias_corrected<sp/>=<sp/></highlight><highlight class="keyword">static_cast&lt;</highlight><highlight class="keywordtype">float</highlight><highlight class="keyword">&gt;</highlight><highlight class="normal">(1<sp/>-<sp/>pow(B1,<sp/>iter));</highlight></codeline>
<codeline lineno="513"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B2_bias_corrected<sp/>=<sp/></highlight><highlight class="keyword">static_cast&lt;</highlight><highlight class="keywordtype">float</highlight><highlight class="keyword">&gt;</highlight><highlight class="normal">(1<sp/>-<sp/>pow(B2,<sp/>iter));</highlight></codeline>
<codeline lineno="514"><highlight class="normal"></highlight></codeline>
<codeline lineno="515"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!_trainable)<sp/>{</highlight></codeline>
<codeline lineno="516"><highlight class="normal"><sp/><sp/><sp/><sp/>cleanupWithinBatchVars();</highlight></codeline>
<codeline lineno="517"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="518"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="519"><highlight class="normal"></highlight></codeline>
<codeline lineno="520"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">/*</highlight></codeline>
<codeline lineno="521"><highlight class="comment"><sp/><sp/><sp/>*<sp/>In<sp/>distributed<sp/>setting,<sp/>as<sp/>of<sp/>now<sp/>the<sp/>updates<sp/>are<sp/>dense<sp/>as<sp/>we</highlight></codeline>
<codeline lineno="522"><highlight class="comment"><sp/><sp/><sp/>*<sp/>are<sp/>averaging<sp/>the<sp/>gradient<sp/>over<sp/>multiple<sp/>training<sp/>examples.</highlight></codeline>
<codeline lineno="523"><highlight class="comment"><sp/><sp/><sp/>*</highlight></codeline>
<codeline lineno="524"><highlight class="comment"><sp/><sp/><sp/>*<sp/>//NOLINT<sp/>because,<sp/>clang<sp/>was<sp/>producing<sp/>error<sp/>as<sp/>same<sp/>function<sp/>is</highlight></codeline>
<codeline lineno="525"><highlight class="comment"><sp/><sp/><sp/>*<sp/>being<sp/>called<sp/>in<sp/>two<sp/>different<sp/>if-else<sp/>blocks.<sp/>However,<sp/>the<sp/>content</highlight></codeline>
<codeline lineno="526"><highlight class="comment"><sp/><sp/><sp/>*<sp/>inside<sp/>the<sp/>_is_distributed<sp/>block<sp/>might<sp/>change<sp/>with<sp/>time.<sp/>Hence,</highlight></codeline>
<codeline lineno="527"><highlight class="comment"><sp/><sp/><sp/>*<sp/>was<sp/>thinking<sp/>of<sp/>having<sp/>different<sp/>blocks.<sp/>It<sp/>also<sp/>make<sp/>is<sp/>visually</highlight></codeline>
<codeline lineno="528"><highlight class="comment"><sp/><sp/><sp/>*<sp/>more<sp/>clear.</highlight></codeline>
<codeline lineno="529"><highlight class="comment"><sp/><sp/><sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="530"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(_is_distributed)<sp/>{<sp/><sp/></highlight><highlight class="comment">//<sp/>NOLINT</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="531"><highlight class="normal"><sp/><sp/><sp/><sp/>updateDenseDenseWeightParameters(lr,<sp/>B1,<sp/>B2,<sp/>eps,<sp/>B1_bias_corrected,</highlight></codeline>
<codeline lineno="532"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>B2_bias_corrected);</highlight></codeline>
<codeline lineno="533"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!_prev_is_dense<sp/>&amp;&amp;<sp/>!_this_is_dense)<sp/>{</highlight></codeline>
<codeline lineno="534"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(_use_sparse_sparse_optimization)<sp/>{</highlight></codeline>
<codeline lineno="535"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>updateSparseSparseWeightParametersOptimized(</highlight></codeline>
<codeline lineno="536"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>lr,<sp/>B1,<sp/>B2,<sp/>eps,<sp/>B1_bias_corrected,<sp/>B2_bias_corrected);</highlight></codeline>
<codeline lineno="537"><highlight class="normal"><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="538"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>updateSparseSparseWeightParametersNormal(</highlight></codeline>
<codeline lineno="539"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>lr,<sp/>B1,<sp/>B2,<sp/>eps,<sp/>B1_bias_corrected,<sp/>B2_bias_corrected);</highlight></codeline>
<codeline lineno="540"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="541"><highlight class="normal"></highlight></codeline>
<codeline lineno="542"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!_prev_is_dense<sp/>&amp;&amp;<sp/>_this_is_dense)<sp/>{</highlight></codeline>
<codeline lineno="543"><highlight class="normal"><sp/><sp/><sp/><sp/>updateSparseDenseWeightParameters(lr,<sp/>B1,<sp/>B2,<sp/>eps,<sp/>B1_bias_corrected,</highlight></codeline>
<codeline lineno="544"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>B2_bias_corrected);</highlight></codeline>
<codeline lineno="545"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(_prev_is_dense<sp/>&amp;&amp;<sp/>!_this_is_dense)<sp/>{</highlight></codeline>
<codeline lineno="546"><highlight class="normal"><sp/><sp/><sp/><sp/>updateDenseSparseWeightParameters(lr,<sp/>B1,<sp/>B2,<sp/>eps,<sp/>B1_bias_corrected,</highlight></codeline>
<codeline lineno="547"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>B2_bias_corrected);</highlight></codeline>
<codeline lineno="548"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="549"><highlight class="normal"><sp/><sp/><sp/><sp/>updateDenseDenseWeightParameters(lr,<sp/>B1,<sp/>B2,<sp/>eps,<sp/>B1_bias_corrected,</highlight></codeline>
<codeline lineno="550"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>B2_bias_corrected);</highlight></codeline>
<codeline lineno="551"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="552"><highlight class="normal"></highlight></codeline>
<codeline lineno="553"><highlight class="normal"><sp/><sp/>updateBiasParameters(lr,<sp/>B1,<sp/>B2,<sp/>eps,<sp/>B1_bias_corrected,<sp/>B2_bias_corrected);</highlight></codeline>
<codeline lineno="554"><highlight class="normal"></highlight></codeline>
<codeline lineno="555"><highlight class="normal"><sp/><sp/>cleanupWithinBatchVars();</highlight></codeline>
<codeline lineno="556"><highlight class="normal">}</highlight></codeline>
<codeline lineno="557"><highlight class="normal"></highlight></codeline>
<codeline lineno="558"><highlight class="normal"></highlight><highlight class="keyword">inline</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::updateSparseSparseWeightParametersOptimized(</highlight></codeline>
<codeline lineno="559"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>lr,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B1,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B2,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>eps,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B1_bias_corrected,</highlight></codeline>
<codeline lineno="560"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B2_bias_corrected)<sp/>{</highlight></codeline>
<codeline lineno="561"><highlight class="normal"></highlight><highlight class="preprocessor">#pragma<sp/>omp<sp/>parallel<sp/>for<sp/>default(none)<sp/>\</highlight></codeline>
<codeline lineno="562"><highlight class="preprocessor"><sp/><sp/><sp/><sp/>shared(lr,<sp/>B1,<sp/>B1_bias_corrected,<sp/>B2,<sp/>B2_bias_corrected,<sp/>eps)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="563"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint32_t<sp/>pair_id<sp/>=<sp/>0;<sp/>pair_id<sp/>&lt;<sp/>_active_pairs_raw.size();<sp/><sp/></highlight><highlight class="comment">//<sp/>NOLINT</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="564"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/>pair_id++)<sp/>{</highlight></codeline>
<codeline lineno="565"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>MSVC<sp/>doesn&apos;t<sp/>like<sp/>if<sp/>we<sp/>iterate<sp/>over<sp/>objects,<sp/>only<sp/>integers</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="566"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>(but<sp/>clang-tidy<sp/>wants<sp/>the<sp/>range<sp/>based<sp/>for<sp/>loop,<sp/>so<sp/>we<sp/>need<sp/>NOLINT</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="567"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>above)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="568"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal">&amp;<sp/>active_pair<sp/>=<sp/>_active_pairs_raw[pair_id];</highlight></codeline>
<codeline lineno="569"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>prev_neuron<sp/>:<sp/>active_pair-&gt;first)<sp/>{</highlight></codeline>
<codeline lineno="570"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>cur_neuron<sp/>:<sp/>active_pair-&gt;second)<sp/>{</highlight></codeline>
<codeline lineno="571"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>uint64_t<sp/>active_pair_index<sp/>=<sp/>cur_neuron<sp/>*<sp/>_prev_dim<sp/>+<sp/>prev_neuron;</highlight></codeline>
<codeline lineno="572"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>This<sp/>is<sp/>a<sp/>race<sp/>condition<sp/>but<sp/>it<sp/>is<sp/>probably<sp/>okay,<sp/>it<sp/>just<sp/>means<sp/>that</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="573"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>we<sp/>might<sp/>by<sp/>mistake<sp/>update<sp/>the<sp/>same<sp/>active<sp/>pair<sp/>twice.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="574"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(_active_pairs_array[active_pair_index])<sp/>{</highlight></codeline>
<codeline lineno="575"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>We<sp/>clean<sp/>_active_pairs_array<sp/>here<sp/>for<sp/>performance</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="576"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_active_pairs_array[active_pair_index]<sp/>=<sp/></highlight><highlight class="keyword">false</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="577"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>updateSingleWeightParameters(prev_neuron,<sp/>cur_neuron,<sp/>lr,<sp/>B1,<sp/>B2,<sp/>eps,</highlight></codeline>
<codeline lineno="578"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>B1_bias_corrected,<sp/>B2_bias_corrected);</highlight></codeline>
<codeline lineno="579"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="580"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="581"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="582"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="583"><highlight class="normal">}</highlight></codeline>
<codeline lineno="584"><highlight class="normal"></highlight></codeline>
<codeline lineno="585"><highlight class="normal"></highlight><highlight class="keyword">inline</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::updateSparseSparseWeightParametersNormal(</highlight></codeline>
<codeline lineno="586"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>lr,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B1,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B2,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>eps,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B1_bias_corrected,</highlight></codeline>
<codeline lineno="587"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B2_bias_corrected)<sp/>{</highlight></codeline>
<codeline lineno="588"><highlight class="normal"></highlight><highlight class="preprocessor">#pragma<sp/>omp<sp/>parallel<sp/>for<sp/>default(none)<sp/>\</highlight></codeline>
<codeline lineno="589"><highlight class="preprocessor"><sp/><sp/><sp/><sp/>shared(lr,<sp/>B1,<sp/>B1_bias_corrected,<sp/>B2,<sp/>B2_bias_corrected,<sp/>eps)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="590"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>cur_neuron<sp/>=<sp/>0;<sp/>cur_neuron<sp/>&lt;<sp/>_dim;<sp/>cur_neuron++)<sp/>{</highlight></codeline>
<codeline lineno="591"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!_is_active[cur_neuron])<sp/>{</highlight></codeline>
<codeline lineno="592"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">continue</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="593"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="594"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>prev_neuron<sp/>=<sp/>0;<sp/>prev_neuron<sp/>&lt;<sp/>_prev_dim;<sp/>prev_neuron++)<sp/>{</highlight></codeline>
<codeline lineno="595"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>uint64_t<sp/>active_pair_index<sp/>=<sp/>cur_neuron<sp/>*<sp/>_prev_dim<sp/>+<sp/>prev_neuron;</highlight></codeline>
<codeline lineno="596"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO(David):<sp/>could<sp/>use<sp/>bloom<sp/>filter<sp/>here<sp/>also?</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="597"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(_active_pairs_array[active_pair_index])<sp/>{</highlight></codeline>
<codeline lineno="598"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>We<sp/>clean<sp/>_active_pairs_array<sp/>here<sp/>for<sp/>performance</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="599"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_active_pairs_array[active_pair_index]<sp/>=<sp/></highlight><highlight class="keyword">false</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="600"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>updateSingleWeightParameters(prev_neuron,<sp/>cur_neuron,<sp/>lr,<sp/>B1,<sp/>B2,<sp/>eps,</highlight></codeline>
<codeline lineno="601"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>B1_bias_corrected,<sp/>B2_bias_corrected);</highlight></codeline>
<codeline lineno="602"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="603"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="604"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="605"><highlight class="normal">}</highlight></codeline>
<codeline lineno="606"><highlight class="normal"></highlight></codeline>
<codeline lineno="607"><highlight class="normal"></highlight><highlight class="keyword">inline</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::updateSparseDenseWeightParameters(</highlight></codeline>
<codeline lineno="608"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>lr,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B1,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B2,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>eps,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B1_bias_corrected,</highlight></codeline>
<codeline lineno="609"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B2_bias_corrected)<sp/>{</highlight></codeline>
<codeline lineno="610"><highlight class="normal"></highlight><highlight class="preprocessor">#pragma<sp/>omp<sp/>parallel<sp/>for<sp/>default(none)<sp/>\</highlight></codeline>
<codeline lineno="611"><highlight class="preprocessor"><sp/><sp/><sp/><sp/>shared(lr,<sp/>B1,<sp/>B1_bias_corrected,<sp/>B2,<sp/>B2_bias_corrected,<sp/>eps)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="612"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>cur_neuron<sp/>=<sp/>0;<sp/>cur_neuron<sp/>&lt;<sp/>_dim;<sp/>cur_neuron++)<sp/>{</highlight></codeline>
<codeline lineno="613"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>prev_neuron<sp/>=<sp/>0;<sp/>prev_neuron<sp/>&lt;<sp/>_prev_dim;<sp/>prev_neuron++)<sp/>{</highlight></codeline>
<codeline lineno="614"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(_prev_is_active[prev_neuron])<sp/>{</highlight></codeline>
<codeline lineno="615"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>updateSingleWeightParameters(prev_neuron,<sp/>cur_neuron,<sp/>lr,<sp/>B1,<sp/>B2,<sp/>eps,</highlight></codeline>
<codeline lineno="616"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>B1_bias_corrected,<sp/>B2_bias_corrected);</highlight></codeline>
<codeline lineno="617"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="618"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="619"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="620"><highlight class="normal">}</highlight></codeline>
<codeline lineno="621"><highlight class="normal"></highlight></codeline>
<codeline lineno="622"><highlight class="normal"></highlight><highlight class="keyword">inline</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::updateDenseSparseWeightParameters(</highlight></codeline>
<codeline lineno="623"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>lr,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B1,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B2,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>eps,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B1_bias_corrected,</highlight></codeline>
<codeline lineno="624"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B2_bias_corrected)<sp/>{</highlight></codeline>
<codeline lineno="625"><highlight class="normal"></highlight><highlight class="preprocessor">#pragma<sp/>omp<sp/>parallel<sp/>for<sp/>default(none)<sp/>\</highlight></codeline>
<codeline lineno="626"><highlight class="preprocessor"><sp/><sp/><sp/><sp/>shared(lr,<sp/>B1,<sp/>B1_bias_corrected,<sp/>B2,<sp/>B2_bias_corrected,<sp/>eps)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="627"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>cur_neuron<sp/>=<sp/>0;<sp/>cur_neuron<sp/>&lt;<sp/>_dim;<sp/>cur_neuron++)<sp/>{</highlight></codeline>
<codeline lineno="628"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!_is_active[cur_neuron])<sp/>{</highlight></codeline>
<codeline lineno="629"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">continue</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="630"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="631"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>prev_neuron<sp/>=<sp/>0;<sp/>prev_neuron<sp/>&lt;<sp/>_prev_dim;<sp/>prev_neuron++)<sp/>{</highlight></codeline>
<codeline lineno="632"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>updateSingleWeightParameters(prev_neuron,<sp/>cur_neuron,<sp/>lr,<sp/>B1,<sp/>B2,<sp/>eps,</highlight></codeline>
<codeline lineno="633"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>B1_bias_corrected,<sp/>B2_bias_corrected);</highlight></codeline>
<codeline lineno="634"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="635"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="636"><highlight class="normal">}</highlight></codeline>
<codeline lineno="637"><highlight class="normal"></highlight></codeline>
<codeline lineno="638"><highlight class="normal"></highlight><highlight class="keyword">inline</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::updateDenseDenseWeightParameters(</highlight></codeline>
<codeline lineno="639"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>lr,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B1,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B2,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>eps,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B1_bias_corrected,</highlight></codeline>
<codeline lineno="640"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B2_bias_corrected)<sp/>{</highlight></codeline>
<codeline lineno="641"><highlight class="normal"></highlight><highlight class="preprocessor">#pragma<sp/>omp<sp/>parallel<sp/>for<sp/>default(none)<sp/>\</highlight></codeline>
<codeline lineno="642"><highlight class="preprocessor"><sp/><sp/><sp/><sp/>shared(lr,<sp/>B1,<sp/>B1_bias_corrected,<sp/>B2,<sp/>B2_bias_corrected,<sp/>eps)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="643"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>cur_neuron<sp/>=<sp/>0;<sp/>cur_neuron<sp/>&lt;<sp/>_dim;<sp/>cur_neuron++)<sp/>{</highlight></codeline>
<codeline lineno="644"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>prev_neuron<sp/>=<sp/>0;<sp/>prev_neuron<sp/>&lt;<sp/>_prev_dim;<sp/>prev_neuron++)<sp/>{</highlight></codeline>
<codeline lineno="645"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>updateSingleWeightParameters(prev_neuron,<sp/>cur_neuron,<sp/>lr,<sp/>B1,<sp/>B2,<sp/>eps,</highlight></codeline>
<codeline lineno="646"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>B1_bias_corrected,<sp/>B2_bias_corrected);</highlight></codeline>
<codeline lineno="647"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="648"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="649"><highlight class="normal">}</highlight></codeline>
<codeline lineno="650"><highlight class="normal"></highlight></codeline>
<codeline lineno="651"><highlight class="normal"></highlight><highlight class="keyword">inline</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::updateBiasParameters(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>lr,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B1,</highlight></codeline>
<codeline lineno="652"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B2,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>eps,</highlight></codeline>
<codeline lineno="653"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B1_bias_corrected,</highlight></codeline>
<codeline lineno="654"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B2_bias_corrected)<sp/>{</highlight></codeline>
<codeline lineno="655"><highlight class="normal"><sp/><sp/>assert(_bias_optimizer.has_value());</highlight></codeline>
<codeline lineno="656"><highlight class="normal"></highlight><highlight class="preprocessor">#pragma<sp/>omp<sp/>parallel<sp/>for<sp/>default(none)<sp/>\</highlight></codeline>
<codeline lineno="657"><highlight class="preprocessor"><sp/><sp/><sp/><sp/>shared(lr,<sp/>B1,<sp/>B1_bias_corrected,<sp/>B2,<sp/>B2_bias_corrected,<sp/>eps)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="658"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>cur_neuron<sp/>=<sp/>0;<sp/>cur_neuron<sp/>&lt;<sp/>_dim;<sp/>cur_neuron++)<sp/>{</highlight></codeline>
<codeline lineno="659"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>((!_is_distributed)<sp/>&amp;&amp;<sp/>(!_this_is_dense<sp/>&amp;&amp;<sp/>!_is_active[cur_neuron]))<sp/>{</highlight></codeline>
<codeline lineno="660"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">continue</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="661"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="662"><highlight class="normal"></highlight></codeline>
<codeline lineno="663"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>grad<sp/>=<sp/>_bias_optimizer-&gt;gradients[cur_neuron];</highlight></codeline>
<codeline lineno="664"><highlight class="normal"><sp/><sp/><sp/><sp/>assert(!std::isnan(grad));</highlight></codeline>
<codeline lineno="665"><highlight class="normal"></highlight></codeline>
<codeline lineno="666"><highlight class="normal"><sp/><sp/><sp/><sp/>_bias_optimizer-&gt;momentum[cur_neuron]<sp/>=</highlight></codeline>
<codeline lineno="667"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>B1<sp/>*<sp/>_bias_optimizer-&gt;momentum[cur_neuron]<sp/>+<sp/>(1<sp/>-<sp/>B1)<sp/>*<sp/>grad;</highlight></codeline>
<codeline lineno="668"><highlight class="normal"><sp/><sp/><sp/><sp/>_bias_optimizer-&gt;velocity[cur_neuron]<sp/>=</highlight></codeline>
<codeline lineno="669"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>B2<sp/>*<sp/>_bias_optimizer-&gt;velocity[cur_neuron]<sp/>+<sp/>(1<sp/>-<sp/>B2)<sp/>*<sp/>grad<sp/>*<sp/>grad;</highlight></codeline>
<codeline lineno="670"><highlight class="normal"></highlight></codeline>
<codeline lineno="671"><highlight class="normal"><sp/><sp/><sp/><sp/>assert(!std::isnan(_bias_optimizer-&gt;momentum[cur_neuron]));</highlight></codeline>
<codeline lineno="672"><highlight class="normal"><sp/><sp/><sp/><sp/>assert(!std::isnan(_bias_optimizer-&gt;velocity[cur_neuron]));</highlight></codeline>
<codeline lineno="673"><highlight class="normal"></highlight></codeline>
<codeline lineno="674"><highlight class="normal"><sp/><sp/><sp/><sp/>_biases[cur_neuron]<sp/>+=</highlight></codeline>
<codeline lineno="675"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>lr<sp/>*<sp/>(_bias_optimizer-&gt;momentum[cur_neuron]<sp/>/<sp/>B1_bias_corrected)<sp/>/</highlight></codeline>
<codeline lineno="676"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>(std::sqrt(_bias_optimizer-&gt;velocity[cur_neuron]<sp/>/<sp/>B2_bias_corrected)<sp/>+</highlight></codeline>
<codeline lineno="677"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>eps);</highlight></codeline>
<codeline lineno="678"><highlight class="normal"><sp/><sp/><sp/><sp/>assert(!std::isnan(_biases[cur_neuron]));</highlight></codeline>
<codeline lineno="679"><highlight class="normal"></highlight></codeline>
<codeline lineno="680"><highlight class="normal"><sp/><sp/><sp/><sp/>_bias_optimizer-&gt;gradients[cur_neuron]<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="681"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="682"><highlight class="normal">}</highlight></codeline>
<codeline lineno="683"><highlight class="normal"></highlight></codeline>
<codeline lineno="684"><highlight class="normal"></highlight><highlight class="keyword">inline</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::cleanupWithinBatchVars()<sp/>{</highlight></codeline>
<codeline lineno="685"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!_this_is_dense<sp/>&amp;&amp;<sp/>!_prev_is_dense)<sp/>{</highlight></codeline>
<codeline lineno="686"><highlight class="normal"><sp/><sp/><sp/><sp/>_active_pairs_raw.clear();</highlight></codeline>
<codeline lineno="687"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>We<sp/>cleanup<sp/>_active_pairs_array<sp/>as<sp/>we<sp/>use<sp/>it<sp/>in<sp/>the<sp/>sparse<sp/>sparse<sp/>weight</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="688"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>update<sp/>methods<sp/>because<sp/>otherwise<sp/>this<sp/>is<sp/>a<sp/>bottleneck.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="689"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="690"><highlight class="normal"><sp/><sp/>std::fill(_prev_is_active.begin(),<sp/>_prev_is_active.end(),<sp/>0);</highlight></codeline>
<codeline lineno="691"><highlight class="normal"><sp/><sp/>std::fill(_is_active.begin(),<sp/>_is_active.end(),<sp/>0);</highlight></codeline>
<codeline lineno="692"><highlight class="normal">}</highlight></codeline>
<codeline lineno="693"><highlight class="normal"></highlight></codeline>
<codeline lineno="694"><highlight class="normal"></highlight><highlight class="keyword">inline</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::updateSingleWeightParameters(</highlight></codeline>
<codeline lineno="695"><highlight class="normal"><sp/><sp/><sp/><sp/>uint64_t<sp/>prev_neuron,<sp/>uint64_t<sp/>cur_neuron,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>lr,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B1,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B2,</highlight></codeline>
<codeline lineno="696"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>eps,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B1_bias_corrected,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>B2_bias_corrected)<sp/>{</highlight></codeline>
<codeline lineno="697"><highlight class="normal"><sp/><sp/>assert(_weight_optimizer.has_value());</highlight></codeline>
<codeline lineno="698"><highlight class="normal"></highlight></codeline>
<codeline lineno="699"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>indx<sp/>=<sp/>cur_neuron<sp/>*<sp/>_prev_dim<sp/>+<sp/>prev_neuron;</highlight></codeline>
<codeline lineno="700"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>grad<sp/>=<sp/>_weight_optimizer-&gt;gradients[indx];</highlight></codeline>
<codeline lineno="701"><highlight class="normal"><sp/><sp/>assert(!std::isnan(grad));</highlight></codeline>
<codeline lineno="702"><highlight class="normal"></highlight></codeline>
<codeline lineno="703"><highlight class="normal"><sp/><sp/>_weight_optimizer-&gt;momentum[indx]<sp/>=</highlight></codeline>
<codeline lineno="704"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>B1<sp/>*<sp/>_weight_optimizer-&gt;momentum[indx]<sp/>+<sp/>(1<sp/>-<sp/>B1)<sp/>*<sp/>grad;</highlight></codeline>
<codeline lineno="705"><highlight class="normal"><sp/><sp/>_weight_optimizer-&gt;velocity[indx]<sp/>=</highlight></codeline>
<codeline lineno="706"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>B2<sp/>*<sp/>_weight_optimizer-&gt;velocity[indx]<sp/>+<sp/>(1<sp/>-<sp/>B2)<sp/>*<sp/>grad<sp/>*<sp/>grad;</highlight></codeline>
<codeline lineno="707"><highlight class="normal"><sp/><sp/>assert(!std::isnan(_weight_optimizer-&gt;momentum[indx]));</highlight></codeline>
<codeline lineno="708"><highlight class="normal"><sp/><sp/>assert(!std::isnan(_weight_optimizer-&gt;velocity[indx]));</highlight></codeline>
<codeline lineno="709"><highlight class="normal"></highlight></codeline>
<codeline lineno="710"><highlight class="normal"><sp/><sp/>_weights[indx]<sp/>+=</highlight></codeline>
<codeline lineno="711"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>lr<sp/>*<sp/>(_weight_optimizer-&gt;momentum[indx]<sp/>/<sp/>B1_bias_corrected)<sp/>/</highlight></codeline>
<codeline lineno="712"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>(std::sqrt(_weight_optimizer-&gt;velocity[indx]<sp/>/<sp/>B2_bias_corrected)<sp/>+<sp/>eps);</highlight></codeline>
<codeline lineno="713"><highlight class="normal"><sp/><sp/>assert(!std::isnan(_weights[indx]));</highlight></codeline>
<codeline lineno="714"><highlight class="normal"></highlight></codeline>
<codeline lineno="715"><highlight class="normal"><sp/><sp/>_weight_optimizer-&gt;gradients[indx]<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="716"><highlight class="normal">}</highlight></codeline>
<codeline lineno="717"><highlight class="normal"></highlight></codeline>
<codeline lineno="718"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::initSamplingDatastructures(</highlight></codeline>
<codeline lineno="719"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>SamplingConfigPtr&amp;<sp/>sampling_config,<sp/>std::random_device&amp;<sp/>rd)<sp/>{</highlight></codeline>
<codeline lineno="720"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(sampling_config-&gt;isRandomSampling())<sp/>{</highlight></codeline>
<codeline lineno="721"><highlight class="normal"><sp/><sp/><sp/><sp/>_sampling_mode<sp/>=<sp/>BoltSamplingMode::RandomSampling;</highlight></codeline>
<codeline lineno="722"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="723"><highlight class="normal"><sp/><sp/><sp/><sp/>_sampling_mode<sp/>=<sp/>BoltSamplingMode::LSH;</highlight></codeline>
<codeline lineno="724"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="725"><highlight class="normal"></highlight></codeline>
<codeline lineno="726"><highlight class="normal"><sp/><sp/>_hasher<sp/>=<sp/>sampling_config-&gt;getHashFunction(_prev_dim);</highlight></codeline>
<codeline lineno="727"><highlight class="normal"></highlight></codeline>
<codeline lineno="728"><highlight class="normal"><sp/><sp/>_hash_table<sp/>=<sp/>sampling_config-&gt;getHashTable();</highlight></codeline>
<codeline lineno="729"><highlight class="normal"></highlight></codeline>
<codeline lineno="730"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">/*<sp/>Initializing<sp/>hence,<sp/>we<sp/>need<sp/>to<sp/>force<sp/>build<sp/>the<sp/>hash<sp/>tables</highlight></codeline>
<codeline lineno="731"><highlight class="comment"><sp/><sp/><sp/>*<sp/>Hence,<sp/>force_build<sp/>is<sp/>true<sp/>here<sp/>in<sp/>buildHashTablesImpl(force_build)</highlight></codeline>
<codeline lineno="732"><highlight class="comment"><sp/><sp/><sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="733"><highlight class="normal"><sp/><sp/>buildHashTablesImpl(</highlight><highlight class="keyword">true</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="734"><highlight class="normal"></highlight></codeline>
<codeline lineno="735"><highlight class="normal"><sp/><sp/>_rand_neurons<sp/>=<sp/>std::vector&lt;uint32_t&gt;(_dim);</highlight></codeline>
<codeline lineno="736"><highlight class="normal"></highlight></codeline>
<codeline lineno="737"><highlight class="normal"><sp/><sp/>std::iota(_rand_neurons.begin(),<sp/>_rand_neurons.end(),<sp/>0);</highlight></codeline>
<codeline lineno="738"><highlight class="normal"><sp/><sp/>std::shuffle(_rand_neurons.begin(),<sp/>_rand_neurons.end(),<sp/>rd);</highlight></codeline>
<codeline lineno="739"><highlight class="normal">}</highlight></codeline>
<codeline lineno="740"><highlight class="normal"></highlight></codeline>
<codeline lineno="741"><highlight class="normal"></highlight><highlight class="keyword">inline</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::deinitSamplingDatastructures()<sp/>{</highlight></codeline>
<codeline lineno="742"><highlight class="normal"><sp/><sp/>_hasher<sp/>=<sp/>{};</highlight></codeline>
<codeline lineno="743"><highlight class="normal"><sp/><sp/>_hash_table<sp/>=<sp/>{};</highlight></codeline>
<codeline lineno="744"><highlight class="normal"><sp/><sp/>_rand_neurons<sp/>=<sp/>{};</highlight></codeline>
<codeline lineno="745"><highlight class="normal">}</highlight></codeline>
<codeline lineno="746"><highlight class="normal"></highlight></codeline>
<codeline lineno="747"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::buildHashTablesImpl(</highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>force_build)<sp/>{</highlight></codeline>
<codeline lineno="748"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>((!_trainable<sp/>&amp;&amp;<sp/>!force_build)<sp/>||<sp/>_sparsity<sp/>&gt;=<sp/>1.0<sp/>||<sp/>hashTablesFrozen()<sp/>||</highlight></codeline>
<codeline lineno="749"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>useRandomSampling())<sp/>{</highlight></codeline>
<codeline lineno="750"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="751"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="752"><highlight class="normal"><sp/><sp/>uint64_t<sp/>num_tables<sp/>=<sp/>_hash_table-&gt;numTables();</highlight></codeline>
<codeline lineno="753"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO(nicholas):<sp/>hashes<sp/>could<sp/>be<sp/>array<sp/>with<sp/>size<sp/>max(batch<sp/>size,<sp/>dim)<sp/>that</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="754"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>is<sp/>allocated<sp/>once</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="755"><highlight class="normal"><sp/><sp/>std::vector&lt;uint32_t&gt;<sp/>hashes(num_tables<sp/>*<sp/>_dim);</highlight></codeline>
<codeline lineno="756"><highlight class="normal"></highlight><highlight class="preprocessor">#pragma<sp/>omp<sp/>parallel<sp/>for<sp/>default(none)<sp/>shared(num_tables,<sp/>hashes)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="757"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(uint64_t<sp/>n<sp/>=<sp/>0;<sp/>n<sp/>&lt;<sp/>_dim;<sp/>n++)<sp/>{</highlight></codeline>
<codeline lineno="758"><highlight class="normal"><sp/><sp/><sp/><sp/>_hasher-&gt;hashSingleDense(_weights.data()<sp/>+<sp/>n<sp/>*<sp/>_prev_dim,<sp/>_prev_dim,</highlight></codeline>
<codeline lineno="759"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>hashes.data()<sp/>+<sp/>n<sp/>*<sp/>num_tables);</highlight></codeline>
<codeline lineno="760"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="761"><highlight class="normal"></highlight></codeline>
<codeline lineno="762"><highlight class="normal"><sp/><sp/>_hash_table-&gt;clearTables();</highlight></codeline>
<codeline lineno="763"><highlight class="normal"><sp/><sp/>_hash_table-&gt;insertSequential(_dim,<sp/>0,<sp/>hashes.data());</highlight></codeline>
<codeline lineno="764"><highlight class="normal">}</highlight></codeline>
<codeline lineno="765"><highlight class="normal"></highlight></codeline>
<codeline lineno="766"><highlight class="normal"></highlight><highlight class="comment">/*<sp/>setting<sp/>force_build<sp/>to<sp/>false.<sp/>force_build<sp/>true<sp/>only<sp/>when<sp/>setting<sp/>weights<sp/>or</highlight></codeline>
<codeline lineno="767"><highlight class="comment"><sp/>*<sp/>initializing</highlight></codeline>
<codeline lineno="768"><highlight class="comment"><sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="769"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::buildHashTables()<sp/>{<sp/>buildHashTablesImpl(</highlight><highlight class="keyword">false</highlight><highlight class="normal">);<sp/>}</highlight></codeline>
<codeline lineno="770"><highlight class="normal"></highlight></codeline>
<codeline lineno="771"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::reBuildHashFunction()<sp/>{</highlight></codeline>
<codeline lineno="772"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!_trainable<sp/>||<sp/>_sparsity<sp/>&gt;=<sp/>1.0<sp/>||<sp/>hashTablesFrozen()<sp/>||</highlight></codeline>
<codeline lineno="773"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>useRandomSampling())<sp/>{</highlight></codeline>
<codeline lineno="774"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="775"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="776"><highlight class="normal"></highlight></codeline>
<codeline lineno="777"><highlight class="normal"><sp/><sp/>_hasher<sp/>=<sp/>_hasher-&gt;copyWithNewSeeds();</highlight></codeline>
<codeline lineno="778"><highlight class="normal">}</highlight></codeline>
<codeline lineno="779"><highlight class="normal"></highlight></codeline>
<codeline lineno="780"><highlight class="normal"></highlight><highlight class="keywordtype">float</highlight><highlight class="normal">*<sp/>FullyConnectedLayer::getWeights()</highlight><highlight class="keyword"><sp/>const<sp/></highlight><highlight class="normal">{</highlight></codeline>
<codeline lineno="781"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal">*<sp/>weights_copy<sp/>=<sp/></highlight><highlight class="keyword">new</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal">[_dim<sp/>*<sp/>_prev_dim];</highlight></codeline>
<codeline lineno="782"><highlight class="normal"><sp/><sp/>std::copy(_weights.begin(),<sp/>_weights.end(),<sp/>weights_copy);</highlight></codeline>
<codeline lineno="783"><highlight class="normal"></highlight></codeline>
<codeline lineno="784"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>weights_copy;</highlight></codeline>
<codeline lineno="785"><highlight class="normal">}</highlight></codeline>
<codeline lineno="786"><highlight class="normal"></highlight></codeline>
<codeline lineno="787"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::setTrainable(</highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>trainable)<sp/>{</highlight></codeline>
<codeline lineno="788"><highlight class="normal"><sp/><sp/>_trainable<sp/>=<sp/>trainable;</highlight></codeline>
<codeline lineno="789"><highlight class="normal">}</highlight></codeline>
<codeline lineno="790"><highlight class="normal"></highlight></codeline>
<codeline lineno="791"><highlight class="normal"></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>FullyConnectedLayer::getTrainable()</highlight><highlight class="keyword"><sp/>const<sp/></highlight><highlight class="normal">{<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>_trainable;<sp/>}</highlight></codeline>
<codeline lineno="792"><highlight class="normal"></highlight></codeline>
<codeline lineno="793"><highlight class="normal"></highlight><highlight class="keywordtype">float</highlight><highlight class="normal">*<sp/>FullyConnectedLayer::getBiases()</highlight><highlight class="keyword"><sp/>const<sp/></highlight><highlight class="normal">{</highlight></codeline>
<codeline lineno="794"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal">*<sp/>biases_copy<sp/>=<sp/></highlight><highlight class="keyword">new</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal">[_dim];</highlight></codeline>
<codeline lineno="795"><highlight class="normal"><sp/><sp/>std::copy(_biases.begin(),<sp/>_biases.end(),<sp/>biases_copy);</highlight></codeline>
<codeline lineno="796"><highlight class="normal"></highlight></codeline>
<codeline lineno="797"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>biases_copy;</highlight></codeline>
<codeline lineno="798"><highlight class="normal">}</highlight></codeline>
<codeline lineno="799"><highlight class="normal"></highlight></codeline>
<codeline lineno="800"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::setWeights(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal">*<sp/>new_weights)<sp/>{</highlight></codeline>
<codeline lineno="801"><highlight class="normal"><sp/><sp/>std::copy(new_weights,<sp/>new_weights<sp/>+<sp/>_dim<sp/>*<sp/>_prev_dim,<sp/>_weights.begin());</highlight></codeline>
<codeline lineno="802"><highlight class="normal"></highlight></codeline>
<codeline lineno="803"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">/*<sp/>Setting<sp/>weights<sp/>=&gt;<sp/>we<sp/>need<sp/>to<sp/>force<sp/>build<sp/>the<sp/>hash<sp/>tables</highlight></codeline>
<codeline lineno="804"><highlight class="comment"><sp/><sp/><sp/>*<sp/>Hence,<sp/>force_build<sp/>is<sp/>true<sp/>here<sp/>in<sp/>buildHashTablesImpl(force_build)</highlight></codeline>
<codeline lineno="805"><highlight class="comment"><sp/><sp/><sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="806"><highlight class="normal"><sp/><sp/>buildHashTablesImpl(</highlight><highlight class="keyword">true</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="807"><highlight class="normal">}</highlight></codeline>
<codeline lineno="808"><highlight class="normal"></highlight></codeline>
<codeline lineno="809"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::setBiases(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal">*<sp/>new_biases)<sp/>{</highlight></codeline>
<codeline lineno="810"><highlight class="normal"><sp/><sp/>std::copy(new_biases,<sp/>new_biases<sp/>+<sp/>_dim,<sp/>_biases.begin());</highlight></codeline>
<codeline lineno="811"><highlight class="normal">}</highlight></codeline>
<codeline lineno="812"><highlight class="normal"></highlight></codeline>
<codeline lineno="813"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::setWeightGradients(</highlight></codeline>
<codeline lineno="814"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal">*<sp/>update_weight_gradient)<sp/>{</highlight></codeline>
<codeline lineno="815"><highlight class="normal"><sp/><sp/>assert(_weight_optimizer.has_value());</highlight></codeline>
<codeline lineno="816"><highlight class="normal"></highlight></codeline>
<codeline lineno="817"><highlight class="normal"><sp/><sp/>std::copy(update_weight_gradient,<sp/>update_weight_gradient<sp/>+<sp/>_dim<sp/>*<sp/>_prev_dim,</highlight></codeline>
<codeline lineno="818"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_weight_optimizer-&gt;gradients.begin());</highlight></codeline>
<codeline lineno="819"><highlight class="normal">}</highlight></codeline>
<codeline lineno="820"><highlight class="normal"></highlight></codeline>
<codeline lineno="821"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::setBiasesGradients(</highlight></codeline>
<codeline lineno="822"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal">*<sp/>update_bias_gradient)<sp/>{</highlight></codeline>
<codeline lineno="823"><highlight class="normal"><sp/><sp/>assert(_bias_optimizer.has_value());</highlight></codeline>
<codeline lineno="824"><highlight class="normal"><sp/><sp/>std::copy(update_bias_gradient,<sp/>update_bias_gradient<sp/>+<sp/>_dim,</highlight></codeline>
<codeline lineno="825"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_bias_optimizer-&gt;gradients.begin());</highlight></codeline>
<codeline lineno="826"><highlight class="normal">}</highlight></codeline>
<codeline lineno="827"><highlight class="normal"></highlight></codeline>
<codeline lineno="828"><highlight class="normal"></highlight><highlight class="keywordtype">float</highlight><highlight class="normal">*<sp/>FullyConnectedLayer::getBiasesGradient()<sp/>{</highlight></codeline>
<codeline lineno="829"><highlight class="normal"><sp/><sp/>assert(_bias_optimizer.has_value());</highlight></codeline>
<codeline lineno="830"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>_bias_optimizer-&gt;gradients.data();</highlight></codeline>
<codeline lineno="831"><highlight class="normal">}</highlight></codeline>
<codeline lineno="832"><highlight class="normal"></highlight></codeline>
<codeline lineno="833"><highlight class="normal"></highlight><highlight class="keywordtype">float</highlight><highlight class="normal">*<sp/>FullyConnectedLayer::getWeightsGradient()<sp/>{</highlight></codeline>
<codeline lineno="834"><highlight class="normal"><sp/><sp/>assert(_weight_optimizer.has_value());</highlight></codeline>
<codeline lineno="835"><highlight class="normal"></highlight></codeline>
<codeline lineno="836"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>_weight_optimizer-&gt;gradients.data();</highlight></codeline>
<codeline lineno="837"><highlight class="normal">}</highlight></codeline>
<codeline lineno="838"><highlight class="normal"></highlight></codeline>
<codeline lineno="839"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::setSparsity(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>sparsity)<sp/>{</highlight></codeline>
<codeline lineno="840"><highlight class="normal"><sp/><sp/>deinitSamplingDatastructures();</highlight></codeline>
<codeline lineno="841"><highlight class="normal"><sp/><sp/>_sparsity<sp/>=<sp/>sparsity;</highlight></codeline>
<codeline lineno="842"><highlight class="normal"></highlight></codeline>
<codeline lineno="843"><highlight class="normal"><sp/><sp/>_sparse_dim<sp/>=<sp/>_sparsity<sp/>*<sp/>_dim;</highlight></codeline>
<codeline lineno="844"><highlight class="normal"></highlight></codeline>
<codeline lineno="845"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO(josh):<sp/>Right<sp/>now<sp/>this<sp/>is<sp/>using<sp/>the<sp/>autotuning<sp/>for<sp/>DWTA<sp/>even<sp/>if<sp/>this</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="846"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>hash<sp/>function<sp/>isn&apos;t<sp/>DWTA.<sp/>Add<sp/>autotuning<sp/>for<sp/>other<sp/>hash<sp/>function<sp/>types.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="847"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(_sparsity<sp/>&lt;<sp/>1.0)<sp/>{</highlight></codeline>
<codeline lineno="848"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">auto</highlight><highlight class="normal"><sp/>sampling_config<sp/>=<sp/>DWTASamplingConfig::autotune(_dim,<sp/>_sparsity);</highlight></codeline>
<codeline lineno="849"><highlight class="normal"><sp/><sp/><sp/><sp/>std::random_device<sp/>rd;</highlight></codeline>
<codeline lineno="850"><highlight class="normal"><sp/><sp/><sp/><sp/>initSamplingDatastructures(sampling_config,<sp/>rd);</highlight></codeline>
<codeline lineno="851"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="852"><highlight class="normal">}</highlight></codeline>
<codeline lineno="853"><highlight class="normal"></highlight></codeline>
<codeline lineno="854"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::initOptimizer()<sp/>{</highlight></codeline>
<codeline lineno="855"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!_weight_optimizer<sp/>||<sp/>!_bias_optimizer)<sp/>{</highlight></codeline>
<codeline lineno="856"><highlight class="normal"><sp/><sp/><sp/><sp/>_weight_optimizer<sp/>=<sp/>AdamOptimizer(_dim<sp/>*<sp/>_prev_dim);</highlight></codeline>
<codeline lineno="857"><highlight class="normal"><sp/><sp/><sp/><sp/>_bias_optimizer<sp/>=<sp/>AdamOptimizer(_dim);</highlight></codeline>
<codeline lineno="858"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="859"><highlight class="normal">}</highlight></codeline>
<codeline lineno="860"><highlight class="normal"></highlight></codeline>
<codeline lineno="861"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::initActiveNeuronsTrackers()<sp/>{</highlight></codeline>
<codeline lineno="862"><highlight class="normal"><sp/><sp/>_active_pairs_array.assign(_dim<sp/>*<sp/>_prev_dim,<sp/></highlight><highlight class="keyword">false</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="863"><highlight class="normal"><sp/><sp/>_prev_is_active.assign(_prev_dim,<sp/></highlight><highlight class="keyword">false</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="864"><highlight class="normal"><sp/><sp/>_is_active.assign(_dim,<sp/></highlight><highlight class="keyword">false</highlight><highlight class="normal">);</highlight></codeline>
<codeline lineno="865"><highlight class="normal"><sp/><sp/>_active_pairs_raw.clear();</highlight></codeline>
<codeline lineno="866"><highlight class="normal">}</highlight></codeline>
<codeline lineno="867"><highlight class="normal"></highlight></codeline>
<codeline lineno="868"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>FullyConnectedLayer::buildLayerSummary(std::stringstream&amp;<sp/>summary,</highlight></codeline>
<codeline lineno="869"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/>detailed)</highlight><highlight class="keyword"><sp/>const<sp/></highlight><highlight class="normal">{</highlight></codeline>
<codeline lineno="870"><highlight class="normal"><sp/><sp/>summary<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;dim=&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>_dim<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;,<sp/>sparsity=&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>_sparsity<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;,<sp/>act_func=&quot;</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="871"><highlight class="normal"><sp/><sp/>summary<sp/>&lt;&lt;<sp/>activationFunctionToStr(_act_func);</highlight></codeline>
<codeline lineno="872"><highlight class="normal"></highlight></codeline>
<codeline lineno="873"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(detailed<sp/>&amp;&amp;<sp/>_sparsity<sp/>&lt;<sp/>1.0)<sp/>{</highlight></codeline>
<codeline lineno="874"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(useRandomSampling())<sp/>{</highlight></codeline>
<codeline lineno="875"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>summary<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;<sp/>(using<sp/>random<sp/>sampling)&quot;</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="876"><highlight class="normal"><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="877"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>summary<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;<sp/>(hash_function=&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>_hasher-&gt;getName()<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;,<sp/>&quot;</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="878"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>_hash_table-&gt;summarize(summary);</highlight></codeline>
<codeline lineno="879"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>summary<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;)&quot;</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="880"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="881"><highlight class="normal"></highlight></codeline>
<codeline lineno="882"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(_use_sparse_sparse_optimization)<sp/>{</highlight></codeline>
<codeline lineno="883"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>summary<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;,<sp/>sparse-sparse<sp/>optimization<sp/>enabled&quot;</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="884"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="885"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="886"><highlight class="normal"></highlight></codeline>
<codeline lineno="887"><highlight class="normal"><sp/><sp/>summary<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;\n&quot;</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="888"><highlight class="normal">}</highlight></codeline>
<codeline lineno="889"><highlight class="normal"></highlight></codeline>
<codeline lineno="890"><highlight class="normal">}<sp/><sp/></highlight><highlight class="comment">//<sp/>namespace<sp/>thirdai::bolt</highlight></codeline>
    </programlisting>
    <location file="bolt/src/layers/FullyConnectedLayer.cc"/>
  </compounddef>
</doxygen>
