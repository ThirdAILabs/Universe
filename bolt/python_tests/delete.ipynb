{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import thirdai\n",
    "from thirdai import bolt_v2 as bolt, dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 200\n",
    "num_examples = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(array, chunksize):\n",
    "    chunks = []\n",
    "    for i in range(0, len(array), chunksize):\n",
    "        chunks.append(np.array(array[i : i + chunksize]))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_labels(input_dim, num_examples):\n",
    "    data = np.random.randint(0, input_dim, size=num_examples, dtype=\"uint32\")\n",
    "    labels_np = data\n",
    "\n",
    "    labels = bolt.train.convert_dataset(\n",
    "        dataset.from_numpy(\n",
    "            labels_np, batch_size = 100\n",
    "        ),\n",
    "        dim = input_dim\n",
    "    )\n",
    "\n",
    "    data = bolt.train.convert_dataset(\n",
    "        dataset.from_numpy(\n",
    "            data, batch_size = 100\n",
    "        ),\n",
    "        dim = input_dim\n",
    "    )\n",
    "    return data, labels, chunk(labels_np, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding_model(use_robez, input_dim, output_dim):\n",
    "    token_input = bolt.nn.Input(dim=input_dim)\n",
    "\n",
    "    if use_robez:\n",
    "        hidden = bolt.nn.RobeZ(\n",
    "            num_embedding_lookups=8,\n",
    "            lookup_size=64,\n",
    "            log_embedding_block_size=29,\n",
    "            update_chunk_size=8,\n",
    "            reduction=\"sum\",\n",
    "        )(token_input)\n",
    "    else:\n",
    "        hidden = bolt.nn.PosEmbedding(\n",
    "            num_embedding_lookups=8,\n",
    "            lookup_size=64,\n",
    "            log_embedding_block_size=29,\n",
    "            update_chunk_size=8,\n",
    "            reduction=\"sum\",\n",
    "        )(token_input)\n",
    "        \n",
    "    output = bolt.nn.FullyConnected(\n",
    "        dim=output_dim, input_dim=hidden.dim(), activation=\"softmax\"\n",
    "    )(hidden)\n",
    "\n",
    "    labels = bolt.nn.Input(dim=output_dim)\n",
    "    loss = bolt.nn.losses.CategoricalCrossEntropy(activations=output, labels=labels)\n",
    "\n",
    "    model = bolt.nn.Model(\n",
    "        inputs=[token_input],\n",
    "        outputs=[output],\n",
    "        losses=[loss],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, train_labels, learning_rate, epochs):\n",
    "    for _ in range(epochs):\n",
    "        for x,y in zip(train_data, train_labels):\n",
    "            model.train_on_batch(x,y)\n",
    "            model.update_parameters(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data, test_labels_np):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y_np in zip(test_data, test_labels_np):\n",
    "        output = model.forward(x, use_sparsity=False)\n",
    "\n",
    "        correct += np.sum(np.argmax(output[0].activations, axis=1) == y_np)\n",
    "        total += len(y_np)\n",
    "    print(f\"Accuracy: {correct/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "robezmodel = generate_embedding_model(True, input_dim = input_dim, output_dim = input_dim)\n",
    "train_data, train_labels, label_chunks = generate_data_labels(input_dim, num_examples)\n",
    "test_data, _, test_labels_np = generate_data_labels(input_dim, num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9962\n"
     ]
    }
   ],
   "source": [
    "train(robezmodel, train_data, train_labels, 0.0001, 3)\n",
    "evaluate(robezmodel, test_data, test_labels_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "posmodel = generate_embedding_model(False, input_dim = input_dim, output_dim = input_dim)\n",
    "train_data, train_labels, label_chunks = generate_data_labels(input_dim, num_examples)\n",
    "test_data, _, test_labels_np = generate_data_labels(input_dim, num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9954\n"
     ]
    }
   ],
   "source": [
    "train(posmodel, train_data, train_labels, 0.0001, 3)\n",
    "evaluate(posmodel, test_data, test_labels_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
