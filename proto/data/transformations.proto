syntax = "proto2";

package proto.data;

import "binning.proto";
import "categorical_temporal.proto";
import "cold_start.proto";
import "cross_column_pairgrams.proto";
import "date.proto";
import "deduplicate_tokens.proto";
import "dyadic_interval.proto";
import "feature_hash.proto";
import "graph.proto";
import "mach_label.proto";
import "recurrence.proto";
import "sequence.proto";
import "string_cast.proto";
import "string_concat.proto";
import "string_hash.proto";
import "string_id_lookup.proto";
import "tabular.proto";
import "text_tokenizer.proto";

message Transformation {
  // We use a nested message here because the List message needs to know about
  // the Transformation message since it contains them, and the Transformation
  // message needs to contain a List message as an option.
  message List {
    repeated Transformation transformations = 1;
  }

  oneof type {
    Binning binning = 1;
    CategoricalTemporal categorical_temporal = 2;
    ColdStart cold_start = 3;
    CountTokens count_tokens = 4;
    CrossColumnPairgrams cross_column_pairgrams = 5;
    Date date = 6;
    DeduplicateTokens deduplicate_tokens = 7;
    DyadicInterval dyadic_interval = 8;
    FeatureHash feature_hash = 9;
    GraphBuilder graph_builder = 10;
    HashedPositionEncoding hashed_position_encoding = 11;
    MachLabel mach_label = 12;
    NeighborFeatures neighbor_features = 13;
    NeighborIds neighbor_ids = 14;
    OffsetPositionEncoding offset_position_encoding = 15;
    RecurrenceAugmentation recurrence_augmentation = 16;
    RegressionBinning regression_binning = 17;
    StringCast string_cast = 18;
    StringConcat string_concat = 19;
    StringHash string_hash = 20;
    StringIDLookup string_id_lookup = 21;
    Tabular tabular = 22;
    TextTokenizer text_tokenizer = 23;
    List list = 24;
  }
}