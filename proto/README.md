# Protobuf in Universe

Protobuf is a serialization library that works by allowing users to define `message` objects in the proto language (think structs), the protobuf compiler is then invoked to generate code that can instantiate, access fields, and serialize these objects. The generated code can be in any language that is supported by the protobuf compiler, for our purposes we will use c++. 

For information about the syntax and how to define `message` objects, please refer to the documentation here: https://protobuf.dev/programming-guides/proto2/

## Best Practices Using Protobuf
1. All new fields should be declared optional, and have logic to handle when they are not present. This is to ensure backwards compatability. Also it is best practice to handle default values in our code, not by adding a default in the proto definition.
2. Do not change existing fields, either by type or name. If such a change needs to be made, depreciate the old field and add a new field with the changed name/type. 
3. Do not reuse field numbers. 
4. If a field depreciated mark is field number as reserved so that it cannot be reused by mistake. 

## Building with Protobuf

### Background

There are two import parts of protobuf that we need for compiling our code. 

The first is `protoc` this is the protobuf compiler. It takes in `.proto` files and generates the c++ header and source files that contain classes which implement the defined protobuf `message` objects. When invoked on a file, say `abc.proto` the compiler will generate `abc.pb.h` and `abc.pb.cc`. These generated classes will contain methods to get and set all of the fields that are defined in the proto file. 

The second thing we need is `libprotobuf`. This library contains the core library and utilities that is used by the generated code to represent different parts of the objects, and also serialize the objects. This library must be linked with our code in order to use the generated protobuf classes. 

### Compiling Our Code

In our codebase the `*.pb.h` and `*.pb.cc` files are never committed to the repository. Instead, when cmake is invoked these files are autogenerated and added to the list of files to be compiled. There are several benefits to this: 
* We don't have to commit large autogenerated files to the repository. 
*  If additions are made to the proto files, then they will be reflected immediately when recompiling. 
* You don't have to worry about rerunning a script ot regenerate the protobuf code everytime a change is made, since it is automatically done. 

In the final link step of the thirdai library we link `protobuf::libprotobuf` along with the other libraries we use such as openmp. 

### Installing Protobuf

Protobuf takes a long time to build from source, thus to save developer time, adding protobuf as a submodule and building it with our code would add at least 5 minutes to every non-incremental build. Hence, our build system uses a tool to find a version of protobuf that is installed on the local machine, which is then used to link `libprotobuf` with our library. 

Protobuf can be installed with `brew install protobuf` on mac, or `sudo apt-get install protobuf-compiler` on linux. 

## Issues Encountered

Here I want to document a few issues I encountered when setting up protobuf, and how they were fixed in case anyone is curious why certain decisions were made. 

### Installying with yum
Yum will only install versions up to protobuf 2.6.1. This only affects building our linux wheels, since the manylinux runner is based on CentOS which uses yum as a package manager. Protobuf 2.6.1 is older and doesn't support some of the newer features of the language that we want. To get around this issue, I added a script `bin/build_protobuf.sh` that will build and install protobuf from source using a newer version of the code. This takes a few minutes to build, but it is only done when building wheels on github actions. 

I also found that building from source with the most recent versions of protobuf 3.23.xx have an issue where abseil and utf8_range don't get linked correctly with protobuf which causes link errors in our library unless we also manually link with abseil and utf8_range as well. Thus we are using version 3.19.3 of protobuf which doens't have these issues. 

### Cross Compiling for MacOS arm 
Cross compiling for MacOS arm was tricky because the protobuf compiler needs to match the architecture of the host machine, since it is invoked on the machine that is doing the compilation, however `libprotobuf` needs to be for MacOS arm in order for it to link correctly. Install protobuf with `brew install protobuf` (since it is cross compiling on x86 MacOS) gives the needed version of `protoc`, but then installs x86 `libprotobuf`. To get around this issue I added a protobuf submodule that is compiled and linked with our library. Since it is compiled with our library it has the same target architecture, and the extra time required for building from source is ok since it's just for building wheels. There is a flag called `THIRDAI_BUILD_PROTOBUF_FROM_SOURCE` that controls if this submodule is built and linked, so that we can avoid the extra time compiling protobuf if there is a preinstalled libary that can be used. 

### Strange Link Errors
Occasionally I noticed some strange link errors or compile warnings in our code that uses the autogenerated protobuf code. This happened to me after making changes to our cmake files, deleting the build directory to force a clean build always resolves it. I also noticed it when switching from a branch that did not contain/use protobuf, to a branch that did. Hopefully once everything is updated to be using protobuf this issue will stop.
